{
  "hash": "f39fd90ebb6f1fb8da3b6230c91362f8",
  "result": {
    "markdown": "# Dates and Times {#sec-datetime}\n\n## {{< fa bullseye >}} Objectives\n\n-   Understand the complexities of working with datetime data\n-   Create datetime formatted data from character and numeric encodings\n-   Format/print datetime data in the desired format\n\n## Why Dates and Times are hard\n\nI'm going to let Tom Scott deliver this portion of the material for me, as his times and timezones video is excellent and entertaining.\n\n::: youtube-video-container\n<iframe src=\"https://www.youtube.com/embed/-5wpm-gesOY\" title=\"The Problem with Time &amp; Timezones - Computerphile\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen>\n\n</iframe>\n:::\n\nThere is also an excellent StackOverflow question @freewindWhySubtractingThese2021 and answers [@skeetAnswerWhySubtracting2011,@borgwardtAnswerWhySubtracting2011] demonstrating exactly how times and time zones can get very confusing even in relatively simple circumstances.\n\nLong story short, we will be using libraries in R and python which handle some of these complexities for us, because dates, times, and timezones are **hard** and we *really* don't want to know exactly how hard they are. The libraries I've chosen for this are `datetime` in Python (used by Pandas), and `lubridate` in R.\n\n::: callout-tip\n## Try It Out - Getting Set up\n\n::: panel-tabset\n### R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## install.packages(\"lubridate\")\nlibrary(lubridate)\n\n# get current date/time\ntoday()\n## [1] \"2023-03-08\"\nnow()\n## [1] \"2023-03-08 08:58:45 CST\"\n```\n:::\n\n\n[Lubridate cheat sheet](https://rawgit.com/rstudio/cheatsheets/main/lubridate.pdf) [Lubridate documentation](https://lubridate.tidyverse.org/)\n\n### Python\n\n\n::: {.cell}\n\n```{.bash .cell-code}\npip install datetime\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nimport datetime\n\ntoday = datetime.date.today()\ntoday\n## datetime.date(2023, 3, 8)\nprint(today)\n## 2023-03-08\nnow = datetime.datetime.now()\nnow\n## datetime.datetime(2023, 3, 8, 8, 58, 47, 19937)\nprint(now)\n## 2023-03-08 08:58:47.019937\n```\n:::\n\n\n[pandas datetime documentation](https://pandas.pydata.org/docs/user_guide/timeseries.html)\n:::\n:::\n\n## Getting Started\n\nLet's differentiate between three types of data which refer to a point in time:\n\n-   a **date**\n-   a **time** within a day\n-   a **date-time** - a specific time on a specific date\n\nNow, let's think about all of the different ways we can specify dates. The table below has examples along with `strptime` formats that are used in both `R` and `python` for telling the computer which date format is used.\n\n+----------+---------------------+----------+---------------------------------------+-------------------+\n|          | Example             | Type     | Notes                                 | `strptime` format |\n+=========:+=====================+==========+=======================================+==================:+\n| 1        | January 12, 2023    | date     | Common in US/N. America               | %B %d, %Y         |\n+----------+---------------------+----------+---------------------------------------+-------------------+\n| 2        | 12 January 2023     | date     | Common in Europe                      | %d %B %Y          |\n+----------+---------------------+----------+---------------------------------------+-------------------+\n| 3        | 01/12/2023          | date     | Common in US                          | %m/%d/%Y          |\n+----------+---------------------+----------+---------------------------------------+-------------------+\n| 4        | 1/12/23             | date     | Common in US                          | %m/%d/%y          |\n+----------+---------------------+----------+---------------------------------------+-------------------+\n| 5        | 12/01/2023          | date     | Common in Europe/Asia                 | %d/%m/%Y          |\n+----------+---------------------+----------+---------------------------------------+-------------------+\n| 6        | 2023-01-12          | date     | ISO 8601 standard\\                    | %Y-%m-%d\\         |\n|          |                     |          | (automatically sorts chronologically) | or %F             |\n+----------+---------------------+----------+---------------------------------------+-------------------+\n| 7        | 12 2023             | date     | day of year + year                    | %j %Y             |\n+----------+---------------------+----------+---------------------------------------+-------------------+\n| 8        | 9:23 PM             | time     | 12h time                              | %I:%M %p          |\n+----------+---------------------+----------+---------------------------------------+-------------------+\n| 9        | 21:23               | time     | 24h time (military time)              | %H:%M\\            |\n|          |                     |          |                                       | or %R             |\n+----------+---------------------+----------+---------------------------------------+-------------------+\n| 10       | 21:23:05            | time     | 24h time (with seconds)               | %H:%M:%S\\         |\n|          |                     |          |                                       | or %T             |\n+----------+---------------------+----------+---------------------------------------+-------------------+\n| 11       | 2023-01-12T21:23:05 | datetime | ISO 8601 international standard       | %FT%T             |\n+----------+---------------------+----------+---------------------------------------+-------------------+\n\n: Different ways to specify dates and times. {#tbl-formats}\n\nNote that rows 4 and 5 of @tbl-formats are ambiguous if you don't know what location your data comes from - the dates could refer to December 1, 2023 or January 12, 2023. This only gets worse if you use 2-digit years.\n\nThere are three main ways that you might want to create a date/time @grolemundDatesTimes:\n\n-   From a string\n-   From individual date/time components\n-   From an existing date/time object\n\n## Creation from Strings\n\nDates and times are often stored in tabular formats as strings. In some cases, these are read in and automatically formatted as date-times, but in other situations, you have to specify the format yourself.\n\n::: callout-demo\n### Demo: Datetimes from Strings\n\nLet's use some data from the US Geological Service with records of earthquakes with magnitude greater than 6 on the Richter scale that occurred between January 1, 2000 and January 1, 2023. You can pull this data yourself using https://earthquake.usgs.gov/earthquakes/map/, but you can also access a CSV of the data [here](https://github.com/srvanderplas/datasets/raw/main/raw/earthquakes2000.csv).\n\n::: panel-tabset\n#### R + lubridate\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lubridate)\nquake <- read.csv(\"https://github.com/srvanderplas/datasets/raw/main/raw/earthquakes2000.csv\")\nstr(quake)\n## 'data.frame':\t3484 obs. of  13 variables:\n##  $ X.EventID        : chr  \"us7000j0n4\" \"nc73821036\" \"us6000j985\" \"us6000j8lp\" ...\n##  $ Time             : chr  \"2022-12-28T16:34:20Z\" \"2022-12-20T10:34:24Z\" \"2022-12-14T18:40:26Z\" \"2022-12-11T14:31:29Z\" ...\n##  $ Latitude         : num  -21.3 40.5 51.6 17.2 -15.3 ...\n##  $ Longitude        : num  171 -124 179 -101 -173 ...\n##  $ Depth.km         : num  10 17.9 73 18 38 ...\n##  $ Author           : chr  \"us\" \"nc\" \"us\" \"us\" ...\n##  $ Catalog          : chr  \"us\" \"nc\" \"us\" \"us\" ...\n##  $ Contributor      : chr  \"us\" \"nc\" \"us\" \"us\" ...\n##  $ ContributorID    : chr  \"us7000j0n4\" \"nc73821036\" \"us6000j985\" \"us6000j8lp\" ...\n##  $ MagType          : chr  \"mww\" \"mw\" \"mww\" \"mww\" ...\n##  $ Magnitude        : num  6.1 6.4 6.3 6 6.8 6.1 6.2 6 7 6.9 ...\n##  $ MagAuthor        : chr  \"us\" \"nc\" \"us\" \"us\" ...\n##  $ EventLocationName: chr  \"southeast of the Loyalty Islands\" \"15km WSW of Ferndale, CA\" \"Rat Islands, Aleutian Islands, Alaska\" \"8 km E of Técpan de Galeana, Mexico\" ...\n```\n:::\n\n\nBy default, `read.csv` reads the time information in as a character variable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readr)\nquake2 <- read_csv(\"https://github.com/srvanderplas/datasets/raw/main/raw/earthquakes2000.csv\")\nstr(quake2)\n## spc_tbl_ [3,484 × 13] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n##  $ #EventID         : chr [1:3484] \"us7000j0n4\" \"nc73821036\" \"us6000j985\" \"us6000j8lp\" ...\n##  $ Time             : POSIXct[1:3484], format: \"2022-12-28 16:34:20\" \"2022-12-20 10:34:24\" ...\n##  $ Latitude         : num [1:3484] -21.3 40.5 51.6 17.2 -15.3 ...\n##  $ Longitude        : num [1:3484] 171 -124 179 -101 -173 ...\n##  $ Depth/km         : num [1:3484] 10 17.9 73 18 38 ...\n##  $ Author           : chr [1:3484] \"us\" \"nc\" \"us\" \"us\" ...\n##  $ Catalog          : chr [1:3484] \"us\" \"nc\" \"us\" \"us\" ...\n##  $ Contributor      : chr [1:3484] \"us\" \"nc\" \"us\" \"us\" ...\n##  $ ContributorID    : chr [1:3484] \"us7000j0n4\" \"nc73821036\" \"us6000j985\" \"us6000j8lp\" ...\n##  $ MagType          : chr [1:3484] \"mww\" \"mw\" \"mww\" \"mww\" ...\n##  $ Magnitude        : num [1:3484] 6.1 6.4 6.3 6 6.8 6.1 6.2 6 7 6.9 ...\n##  $ MagAuthor        : chr [1:3484] \"us\" \"nc\" \"us\" \"us\" ...\n##  $ EventLocationName: chr [1:3484] \"southeast of the Loyalty Islands\" \"15km WSW of Ferndale, CA\" \"Rat Islands, Aleutian Islands, Alaska\" \"8 km E of Técpan de Galeana, Mexico\" ...\n##  - attr(*, \"spec\")=\n##   .. cols(\n##   ..   `#EventID` = col_character(),\n##   ..   Time = col_datetime(format = \"\"),\n##   ..   Latitude = col_double(),\n##   ..   Longitude = col_double(),\n##   ..   `Depth/km` = col_double(),\n##   ..   Author = col_character(),\n##   ..   Catalog = col_character(),\n##   ..   Contributor = col_character(),\n##   ..   ContributorID = col_character(),\n##   ..   MagType = col_character(),\n##   ..   Magnitude = col_double(),\n##   ..   MagAuthor = col_character(),\n##   ..   EventLocationName = col_character()\n##   .. )\n##  - attr(*, \"problems\")=<externalptr>\n```\n:::\n\n\nHowever, if we use `readr::read_csv`, the data is correctly read in as a `POSIXct` format, which is how R indicates that something is a datetime object.\n\nIf we want to directly convert the Time column in `quake` to a datetime, we can use the `lubridate` package, which has helper functions `ymd_hms`, `ymd`, and more. Our data is formatted in ISO 8601 standard format, which means we can easily read it in with `ymd_hms()` .\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lubridate)\nlibrary(dplyr)\nquake <- quake %>% \n  mutate(dateTime = ymd_hms(Time))\nstr(quake)\n## 'data.frame':\t3484 obs. of  14 variables:\n##  $ X.EventID        : chr  \"us7000j0n4\" \"nc73821036\" \"us6000j985\" \"us6000j8lp\" ...\n##  $ Time             : chr  \"2022-12-28T16:34:20Z\" \"2022-12-20T10:34:24Z\" \"2022-12-14T18:40:26Z\" \"2022-12-11T14:31:29Z\" ...\n##  $ Latitude         : num  -21.3 40.5 51.6 17.2 -15.3 ...\n##  $ Longitude        : num  171 -124 179 -101 -173 ...\n##  $ Depth.km         : num  10 17.9 73 18 38 ...\n##  $ Author           : chr  \"us\" \"nc\" \"us\" \"us\" ...\n##  $ Catalog          : chr  \"us\" \"nc\" \"us\" \"us\" ...\n##  $ Contributor      : chr  \"us\" \"nc\" \"us\" \"us\" ...\n##  $ ContributorID    : chr  \"us7000j0n4\" \"nc73821036\" \"us6000j985\" \"us6000j8lp\" ...\n##  $ MagType          : chr  \"mww\" \"mw\" \"mww\" \"mww\" ...\n##  $ Magnitude        : num  6.1 6.4 6.3 6 6.8 6.1 6.2 6 7 6.9 ...\n##  $ MagAuthor        : chr  \"us\" \"nc\" \"us\" \"us\" ...\n##  $ EventLocationName: chr  \"southeast of the Loyalty Islands\" \"15km WSW of Ferndale, CA\" \"Rat Islands, Aleutian Islands, Alaska\" \"8 km E of Técpan de Galeana, Mexico\" ...\n##  $ dateTime         : POSIXct, format: \"2022-12-28 16:34:20\" \"2022-12-20 10:34:24\" ...\n```\n:::\n\n\nWe can then test whether `quake$dateTime` is the same as `quake2$Time` :\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall.equal(quake2$Time, quake$dateTime)\n## [1] TRUE\n```\n:::\n\n\nSo in the case that your data is not automatically read in as a date-time, you can use the helper functions from lubridate (`ymd_hms`, `ymd`, `mdy`, ...) to convert strings to date-time data.\n\n#### Base R\n\nAs lovely as the lubridate package is, there are some situations where using the tidyverse may not be desirable or even allowed. It is helpful to know how to solve this problem in base R, even if 99% of the time we can use the much easier-to-remember lubridate package.\n\nIn this case, we would use the `as.POSIXct` function, and we probably want to have the reference page up (run `?strptime` in the R console to pull up the help page).\n\nWe'll need to get the codes that tell R what format our datetimes use - you can use @tbl-formats, if you like, or read the `as.POSIXct` help page to see all possible format codes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquake <- read.csv(\"https://github.com/srvanderplas/datasets/raw/main/raw/earthquakes2000.csv\")\nstr(quake)\n## 'data.frame':\t3484 obs. of  13 variables:\n##  $ X.EventID        : chr  \"us7000j0n4\" \"nc73821036\" \"us6000j985\" \"us6000j8lp\" ...\n##  $ Time             : chr  \"2022-12-28T16:34:20Z\" \"2022-12-20T10:34:24Z\" \"2022-12-14T18:40:26Z\" \"2022-12-11T14:31:29Z\" ...\n##  $ Latitude         : num  -21.3 40.5 51.6 17.2 -15.3 ...\n##  $ Longitude        : num  171 -124 179 -101 -173 ...\n##  $ Depth.km         : num  10 17.9 73 18 38 ...\n##  $ Author           : chr  \"us\" \"nc\" \"us\" \"us\" ...\n##  $ Catalog          : chr  \"us\" \"nc\" \"us\" \"us\" ...\n##  $ Contributor      : chr  \"us\" \"nc\" \"us\" \"us\" ...\n##  $ ContributorID    : chr  \"us7000j0n4\" \"nc73821036\" \"us6000j985\" \"us6000j8lp\" ...\n##  $ MagType          : chr  \"mww\" \"mw\" \"mww\" \"mww\" ...\n##  $ Magnitude        : num  6.1 6.4 6.3 6 6.8 6.1 6.2 6 7 6.9 ...\n##  $ MagAuthor        : chr  \"us\" \"nc\" \"us\" \"us\" ...\n##  $ EventLocationName: chr  \"southeast of the Loyalty Islands\" \"15km WSW of Ferndale, CA\" \"Rat Islands, Aleutian Islands, Alaska\" \"8 km E of Técpan de Galeana, Mexico\" ...\nquake$dateTime2 <- as.POSIXct(quake$Time, \"%Y-%m-%dT%H:%M:%S\")\nall.equal(quake$dateTime, quake$dateTime2)\n## [1] TRUE\n```\n:::\n\n\nSo using `as.POSIXct` we do not get the convenient handling of time zones that we got using `ymd_hms`, but we can set the time zone explicitly if we want to do so.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquake$dateTime2 <- as.POSIXct(quake$Time, tz = \"UTC\", \"%Y-%m-%dT%H:%M:%S\")\nall.equal(quake$dateTime, quake$dateTime2)\n## [1] TRUE\n```\n:::\n\n\n#### Pandas\n\nIn pandas, we can use the `to_datetime` method. If the format is not specified, pandas will try to guess the date-time format; in this case, the guess works, but if not, you can provide a `format = …` argument that works the same way as R.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nquake = pd.read_csv(\"https://github.com/srvanderplas/datasets/raw/main/raw/earthquakes2000.csv\")\nquake.dtypes\n## #EventID              object\n## Time                  object\n## Latitude             float64\n## Longitude            float64\n## Depth/km             float64\n## Author                object\n## Catalog               object\n## Contributor           object\n## ContributorID         object\n## MagType               object\n## Magnitude            float64\n## MagAuthor             object\n## EventLocationName     object\n## dtype: object\nquake.Time[0:10]\n\n# Convert to datetime\n## 0    2022-12-28T16:34:20Z\n## 1    2022-12-20T10:34:24Z\n## 2    2022-12-14T18:40:26Z\n## 3    2022-12-11T14:31:29Z\n## 4    2022-12-04T19:24:15Z\n## 5    2022-11-23T01:08:15Z\n## 6    2022-11-22T16:39:05Z\n## 7    2022-11-22T02:37:57Z\n## 8    2022-11-22T02:03:06Z\n## 9    2022-11-18T13:37:08Z\n## Name: Time, dtype: object\nquake['dateTime'] = pd.to_datetime(quake.Time)\nquake.dtypes\n## #EventID                          object\n## Time                              object\n## Latitude                         float64\n## Longitude                        float64\n## Depth/km                         float64\n## Author                            object\n## Catalog                           object\n## Contributor                       object\n## ContributorID                     object\n## MagType                           object\n## Magnitude                        float64\n## MagAuthor                         object\n## EventLocationName                 object\n## dateTime             datetime64[ns, UTC]\n## dtype: object\nquake.dateTime[0:10]\n\n# Convert to datetime\n## 0   2022-12-28 16:34:20+00:00\n## 1   2022-12-20 10:34:24+00:00\n## 2   2022-12-14 18:40:26+00:00\n## 3   2022-12-11 14:31:29+00:00\n## 4   2022-12-04 19:24:15+00:00\n## 5   2022-11-23 01:08:15+00:00\n## 6   2022-11-22 16:39:05+00:00\n## 7   2022-11-22 02:37:57+00:00\n## 8   2022-11-22 02:03:06+00:00\n## 9   2022-11-18 13:37:08+00:00\n## Name: dateTime, dtype: datetime64[ns, UTC]\nquake['dateTime2'] = pd.to_datetime(quake.Time, format = \"%Y-%m-%dT%H:%M:%S\")\nquake.dtypes\n## #EventID                          object\n## Time                              object\n## Latitude                         float64\n## Longitude                        float64\n## Depth/km                         float64\n## Author                            object\n## Catalog                           object\n## Contributor                       object\n## ContributorID                     object\n## MagType                           object\n## Magnitude                        float64\n## MagAuthor                         object\n## EventLocationName                 object\n## dateTime             datetime64[ns, UTC]\n## dateTime2            datetime64[ns, UTC]\n## dtype: object\nquake.dateTime2[0:10]\n## 0   2022-12-28 16:34:20+00:00\n## 1   2022-12-20 10:34:24+00:00\n## 2   2022-12-14 18:40:26+00:00\n## 3   2022-12-11 14:31:29+00:00\n## 4   2022-12-04 19:24:15+00:00\n## 5   2022-11-23 01:08:15+00:00\n## 6   2022-11-22 16:39:05+00:00\n## 7   2022-11-22 02:37:57+00:00\n## 8   2022-11-22 02:03:06+00:00\n## 9   2022-11-18 13:37:08+00:00\n## Name: dateTime2, dtype: datetime64[ns, UTC]\n```\n:::\n\n:::\n:::\n\n::: callout-tip\n### Try it Out - Datetimes from Strings\n\nIt's usually important for new parents to keep a log of the new baby's feeds, to ensure that the baby is getting enough liquids and isn't getting dehydrated. \nI used an app to keep track of my daughter's feeds from birth (though here, we'll only work with [the first month of data](https://raw.githubusercontent.com/srvanderplas/datasets/main/raw/feeds_first_month.csv)), and it used a reasonable, if not standard way to store dates and times. \n\n::: panel-tabset\n#### Problem\n\nTake a look at the [first month of feeds](https://raw.githubusercontent.com/srvanderplas/datasets/main/raw/feeds_first_month.csv).\nNote that these data are from August 7, 2021 to November 4, 2021 -- roughly baby's first 90 days.\n\n1. Convert Start and End to datetime variables\n2. Can you plot the feeds somehow?\n3. Can you do arithmetic with datetimes to see if there are any user entry errors?    \nThis data was created by a *highly* unreliable and error prone couple of individuals -- specifically, sleep-deprived new parents. \n\nTo do this, you may need to figure out how to specify a non-standard date format in R and/or python. The `parse_date_time` function is useful in R, and `pd.to_datetime()` takes a format argument in python.\n\n\n#### R solution\n\nFirst, let's read the data in and explore a bit.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lubridate)\nlibrary(readr)\nfeeds <- read_csv(\"https://raw.githubusercontent.com/srvanderplas/datasets/main/raw/feeds_initial.csv\")\nhead(feeds)\n## # A tibble: 6 × 6\n##      id Start               End                 Type   `Quantity (oz)` Quantit…¹\n##   <dbl> <chr>               <chr>               <chr>            <dbl>     <dbl>\n## 1  1368 20:03:30 11-04-2021 20:45:21 11-04-2021 Breast              NA        NA\n## 2  1366 18:00:29 11-04-2021 18:18:29 11-04-2021 Breast              NA        NA\n## 3  1365 16:27:29 11-04-2021 17:03:26 11-04-2021 Breast              NA        NA\n## 4  1364 14:30:01 11-04-2021 14:42:05 11-04-2021 Breast              NA        NA\n## 5  1367 12:48:29 11-04-2021 13:50:29 11-04-2021 Bottle               3        88\n## 6  1363 10:59:18 11-04-2021 11:15:18 11-04-2021 Bottle               3        88\n## # … with abbreviated variable name ¹​`Quantity (ml or g)`\n\n# Looks like %H:%M:%S %m-%d-%Y format.\n```\n:::\n\n\nIt looks like the data is stored in a format where the time (`%H:%M:%S`) is first and the date (`%m-%d-%Y`) is second. We can use the `parse_date_time` function in lubridate\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfeeds <- feeds %>%\n  mutate(Start = parse_date_time(Start, orders = c(\"%H:%M:%S %m-%d-%Y\")),\n         End = parse_date_time(End, orders = c(\"%H:%M:%S %m-%d-%Y\")))\n```\n:::\n\n\nLet's then explore how we might plot this data: \n\n\n::: {.cell fig.caption='Feeds in the first 90 days of an infant\\'s life.'}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nggplot(feeds, aes(xmin = Start, xmax = End, fill = Type)) + \n  geom_rect(aes(ymin = 1, ymax = 2)) + # Specify default aes\n  scale_fill_manual(values = c(\"Bottle\" = \"cornflowerblue\", \"Breast\" = \"pink\")) + \n  theme_bw() + theme(legend.position = \"bottom\") + \n  scale_y_continuous(breaks = NULL)\n```\n\n::: {.cell-output-display}\n![](07-datetime_files/figure-html/unnamed-chunk-13-1.png){width=1800}\n:::\n:::\n\n::: {.cell fig.caption='Feeds in the first 90 days of an infant\\'s life, by hour of the day.'}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nfeeds %>%\n  mutate(day = floor_date(Start, \"day\"),\n         hour_start = Start - day,\n         hour_end = End - day) %>%\n  mutate(across(starts_with(\"hour\"), ~as.numeric(., units = \"hours\"))) %>%\n  mutate(doy = yday(day)) %>%\nggplot(aes(ymin = day, ymax = day+days(1), xmin = hour_start, xmax = hour_end, fill = Type)) + \n  geom_rect() + # Specify default aes\n  scale_fill_manual(values = c(\"Bottle\" = \"cornflowerblue\", \"Breast\" = \"pink\")) + \n  scale_x_continuous(\"Hour of the day\") + \n  theme_bw() + theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](07-datetime_files/figure-html/unnamed-chunk-14-1.png){width=1800}\n:::\n:::\n\n\nWe can also calculate the duration of each feed and look at the distributions for each type of feed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfeeds <- feeds %>%\n  mutate(duration = End - Start)\n\nggplot(feeds, aes(x = duration, fill = Type)) + geom_histogram(color = \"black\") + \n  scale_fill_manual(values = c(\"Bottle\" = \"cornflowerblue\", \"Breast\" = \"pink\")) + \n  theme_bw() + theme(legend.position = \"none\") + \n  xlab(\"Feed duration, in seconds\") + facet_wrap(~Type)\n```\n\n::: {.cell-output-display}\n![](07-datetime_files/figure-html/unnamed-chunk-15-1.png){width=2100}\n:::\n:::\n\n\nWe can see a few suspiciously long feeds - 9000 seconds is 2.5 hours, which is not unheard of for a baby to breastfeed, but would be an exceptionally long bottle feed (unless a parent fell asleep before hitting \"stop\" on the feed, which is much more likely). \n\n\n#### Python solution\n\n\nFirst, let's read the data in and explore a bit.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\n\nfeeds = pd.read_csv(\"https://raw.githubusercontent.com/srvanderplas/datasets/main/raw/feeds_initial.csv\")\nfeeds.head()\n\n# Looks like %H:%M:%S %m-%d-%Y format.\n##      id                Start  ... Quantity (oz) Quantity (ml or g)\n## 0  1368  20:03:30 11-04-2021  ...           NaN                NaN\n## 1  1366  18:00:29 11-04-2021  ...           NaN                NaN\n## 2  1365  16:27:29 11-04-2021  ...           NaN                NaN\n## 3  1364  14:30:01 11-04-2021  ...           NaN                NaN\n## 4  1367  12:48:29 11-04-2021  ...           3.0               88.0\n## \n## [5 rows x 6 columns]\n```\n:::\n\n\nIt looks like the data is stored in a format where the time (`%H:%M:%S`) is first and the date (`%m-%d-%Y`) is second. We can use the format argument to `pd.to_datetime` to specify this:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfeeds[\"Start\"] = pd.to_datetime(feeds.Start, format = \"%H:%M:%S %m-%d-%Y\")\nfeeds[\"End\"] = pd.to_datetime(feeds.End, format = \"%H:%M:%S %m-%d-%Y\")\nfeeds.head()\n##      id               Start  ... Quantity (oz) Quantity (ml or g)\n## 0  1368 2021-11-04 20:03:30  ...           NaN                NaN\n## 1  1366 2021-11-04 18:00:29  ...           NaN                NaN\n## 2  1365 2021-11-04 16:27:29  ...           NaN                NaN\n## 3  1364 2021-11-04 14:30:01  ...           NaN                NaN\n## 4  1367 2021-11-04 12:48:29  ...           3.0               88.0\n## \n## [5 rows x 6 columns]\n```\n:::\n\n\nIn Python, it is helpful to do a bit of transformation first - this is partly because I'm not as good with Python plotting systems.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport datetime as dt\nfeeds[\"day\"] = feeds.Start.dt.strftime(\"%Y-%m-%d\")\nfeeds[\"day\"] = pd.to_datetime(feeds.day, format = \"%Y-%m-%d\")\nfeeds[\"day_end\"] = feeds.day + dt.timedelta(days = 1)\n\nfeeds[\"time_start\"] = feeds.Start - feeds.day\nfeeds[\"time_end\"] = feeds.End - feeds.day\nfeeds[\"duration\"] = feeds.time_end - feeds.time_start\n```\n:::\n\n\nNote that as of January 2023, RStudio does not correctly display timedelta data types in python.\nThey show up as NAs in the table, but are printed fine in the console. \nDon't spend hours trying to figure out why it isn't working -- it's bad enough that I did.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom plotnine import *\n\n(\n  ggplot(feeds, aes(xmin = \"Start\", xmax = \"End\", fill = \"Type\")) + \n  geom_rect(aes(ymin = 1, ymax = 2)) + \n  scale_fill_manual(values = [\"cornflowerblue\", \"pink\"]) + \n  theme_bw() + scale_y_continuous(breaks = [])\n)\n## <ggplot: (8741325627765)>\n```\n\n::: {.cell-output-display}\n![](07-datetime_files/figure-html/unnamed-chunk-19-1.png){width=614}\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom plotnine import *\n\n(\n  ggplot(feeds, aes(xmin = \"time_start\", xmax = \"time_end\", ymin = \"day\", ymax = \"day_end\", fill = \"Type\")) + \n  geom_rect() + \n  scale_fill_manual(values = [\"cornflowerblue\", \"pink\"]) + \n  theme_bw()\n)\n## <ggplot: (8741298741552)>\n```\n\n::: {.cell-output-display}\n![](07-datetime_files/figure-html/unnamed-chunk-20-3.png){width=614}\n:::\n:::\n\n\n:::\n\n:::\n\n## Creation from Components\n\nSometimes, instead of a single string, you'll have the individual components of the date-time spread across columns. \nThe `nycflights13` data is a good example of this.\n\n::: callout-demo\n### Demo: Datetimes from Components\n\n::: panel-tabset\n\n#### R + lubridate\n\nIn `lubridate`, the `make_date()` and `make_datetime()` functions can be used to create date-times from component pieces.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(nycflights13)\n\nflights %>%\n  select(year, month, day, hour, minute) %>% \n  head()\n## # A tibble: 6 × 5\n##    year month   day  hour minute\n##   <int> <int> <int> <dbl>  <dbl>\n## 1  2013     1     1     5     15\n## 2  2013     1     1     5     29\n## 3  2013     1     1     5     40\n## 4  2013     1     1     5     45\n## 5  2013     1     1     6      0\n## 6  2013     1     1     5     58\n\nflights <- flights %>%\n  mutate(date = make_date(year, month, day),\n         datetime = make_datetime(year, month, day, hour, minute))\n\nflights %>% select(date, datetime, year, month, day, hour, minute)\n## # A tibble: 336,776 × 7\n##    date       datetime             year month   day  hour minute\n##    <date>     <dttm>              <int> <int> <int> <dbl>  <dbl>\n##  1 2013-01-01 2013-01-01 05:15:00  2013     1     1     5     15\n##  2 2013-01-01 2013-01-01 05:29:00  2013     1     1     5     29\n##  3 2013-01-01 2013-01-01 05:40:00  2013     1     1     5     40\n##  4 2013-01-01 2013-01-01 05:45:00  2013     1     1     5     45\n##  5 2013-01-01 2013-01-01 06:00:00  2013     1     1     6      0\n##  6 2013-01-01 2013-01-01 05:58:00  2013     1     1     5     58\n##  7 2013-01-01 2013-01-01 06:00:00  2013     1     1     6      0\n##  8 2013-01-01 2013-01-01 06:00:00  2013     1     1     6      0\n##  9 2013-01-01 2013-01-01 06:00:00  2013     1     1     6      0\n## 10 2013-01-01 2013-01-01 06:00:00  2013     1     1     6      0\n## # … with 336,766 more rows\n```\n:::\n\n\n#### Base R\n\nIn base R, we can use the `ISOdate` function to create date times.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights$datetime_base = with(flights, ISOdatetime(year, month, day, hour, minute, sec= 0, tz=\"UTC\"))\nall.equal(flights$datetime, flights$datetime_base)\n## [1] TRUE\n```\n:::\n\n\n#### Python\n\nIn pandas, we can pass multiple columns to `pd.to_datetime()` and as long as they are named reasonably, pandas will handle the conversion.\nIf we want to have the date but not the time for some reason, we just pass fewer columns to pandas.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom nycflights13 import flights\n\nflights[[\"year\", \"month\", \"day\", \"hour\", \"minute\"]]\n##         year  month  day  hour  minute\n## 0       2013      1    1     5      15\n## 1       2013      1    1     5      29\n## 2       2013      1    1     5      40\n## 3       2013      1    1     5      45\n## 4       2013      1    1     6       0\n## ...      ...    ...  ...   ...     ...\n## 336771  2013      9   30    14      55\n## 336772  2013      9   30    22       0\n## 336773  2013      9   30    12      10\n## 336774  2013      9   30    11      59\n## 336775  2013      9   30     8      40\n## \n## [336776 rows x 5 columns]\nflights[\"date\"] = pd.to_datetime(flights[[\"year\", \"month\", \"day\"]])\nflights[\"datetime\"] = pd.to_datetime(flights[[\"year\", \"month\", \"day\", \"hour\", \"minute\"]])\n\n\nflights[[\"date\", \"datetime\", \"year\", \"month\", \"day\", \"hour\", \"minute\"]]\n##              date            datetime  year  month  day  hour  minute\n## 0      2013-01-01 2013-01-01 05:15:00  2013      1    1     5      15\n## 1      2013-01-01 2013-01-01 05:29:00  2013      1    1     5      29\n## 2      2013-01-01 2013-01-01 05:40:00  2013      1    1     5      40\n## 3      2013-01-01 2013-01-01 05:45:00  2013      1    1     5      45\n## 4      2013-01-01 2013-01-01 06:00:00  2013      1    1     6       0\n## ...           ...                 ...   ...    ...  ...   ...     ...\n## 336771 2013-09-30 2013-09-30 14:55:00  2013      9   30    14      55\n## 336772 2013-09-30 2013-09-30 22:00:00  2013      9   30    22       0\n## 336773 2013-09-30 2013-09-30 12:10:00  2013      9   30    12      10\n## 336774 2013-09-30 2013-09-30 11:59:00  2013      9   30    11      59\n## 336775 2013-09-30 2013-09-30 08:40:00  2013      9   30     8      40\n## \n## [336776 rows x 7 columns]\n```\n:::\n\n\n:::\n:::\n\n\n<!-- ## Creation from other objects -->\n\n<!-- Another way to create date-time objects is to modify other objects.  -->\n\n## References",
    "supporting": [
      "07-datetime_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}