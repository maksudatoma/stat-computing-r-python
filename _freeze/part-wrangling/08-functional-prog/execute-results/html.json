{
  "hash": "ba4462f91ecfb303eb6663d2380b7d18",
  "result": {
    "markdown": "# Functional Programming {#sec-lists}\n\nIn this section, we're going to change focus slightly from learning specific functions to learning programming **patterns**. \nWe're going to start this process by talking about functional programming and its connection to lists. \nWhile this topic may be a bit advanced if you're just starting to learn how to program, it may help to skim through the deeper explanation so that you can at least recognize some of these words if you encounter them later.\n\n## Programming Philosophies\n\n::: callout-advanced\nThis section is intended for everyone, but I do not expect that people who are just learning to program for the first time will fully absorb everything in this section. \nGet what you can out of this, use it to improve how you write code, and come back to it later if it's too confusing.\n:::\n\nJust as spoken languages fall into families, like Indo-European or Sino-Tibetan, programming languages also have broad classifications. \nHere are a few \"families\" or classifications of programming languages [@kuchlingFunctionalProgrammingHOWTO2022]:\n\n- Many languages are **procedural**: a program provides a list of instructions that tell the computer what to do with provided input. C, Pascal, Fortran, and UNIX shells are naturally procedural. JavaScript is also a fairly natural procedural language. Many R analysis scripts are also naturally written in a procedural style; SAS code is almost always procedural.\n- **Declarative languages** use code to describe the problem that needs to be solved, and the language figures out how to solve it. SQL is the most common declarative language you'll encounter for data-related tasks.\n- **Object oriented** languages (sometimes abbreviated OOP, for object-oriented programming) manipulate collections of objects or classes. Data is stored in classes that have associated functions, which are often called methods. Java is explicitly object-oriented; C++ and Python support object-oriented programming but don't force you to use those features.\n- **Functional** programming languages describe a problem using a set of functions, which only take inputs and produce outputs. Functions don't have any internal tracking of **state** - purely functional languages move from input to output without storing variables or even printing output to the command line, but it is common to adopt a functional approach to programming without requiring strict adherence to all principles of a fully functional approach. Haskell and Rust are fairly standard functional programming languages.\n\n\n::: {.youtube-video-container .aside}\nHadley's talk on The Joy of Functional Programming for Data Science\n\n<iframe width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/bzUmK0Y07ck\" title=\"&quot;The Joy of Functional Programming (for Data Science)&quot; with Hadley Wickham\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n:::\n\n\nFunctional programming languages have a goal of writing **pure functions** - functions that do not change the global state (stuff stored in objects, memory, parameters, or files) of the program and thus have no side effects. \nThe return value of a pure function is based solely on the inputs to the function.\nNot all functions can be pure functions - for instance, there's no pure way to do file IO operations. \nBut it is a nice goal to be able to move parameters into functions and have the correct object returned from that function, so that you can pipe multiple operations together into a pipeline.\n\nMost general-purpose languages like C++ and Python and even some domain languages like R support multiple different programming paradigms. \nWhile preparing to write this chapter, I saw functional programming books with examples in Java [@urmaModernJavaAction2018], JavaScript [@FPJS], and C# [@buonannoFunctionalProgrammingHow2017] - all languages that I would associate with OOP or procedural styles.\nI also found books teaching object oriented programming using Fortran 90-95 [@OOPfortran], which is something I wouldn't have considered possible.\n\nAll of this is to say that while certain languages are built around principles like OOP or functional programming, almost every language has users who rely more heavily on one approach than the other. \nThere are very few \"pure\" programming languages, which reminds me of one of my favorite quotes about English: \n\n> \"The problem with defending the purity of the English language is that English is about as pure as a cribhouse whore. We don't just borrow words; on occasion, English has pursued other languages down alleyways to beat them unconscious and rifle their pockets for new vocabulary.\" ― [James D. Nicoll](https://www.goodreads.com/quotes/694108-the-problem-with-defending-the-purity-of-the-english-language)\n\n::: callout-demo\n### Object Oriented Philosophy in R and Python\n::: panel-tabset\n#### Python\n\nWhen you call `df.size()` in Python, you are calling the `size` method that is part of the `df` object, which is a `DataFrame`. \nThis suggests that Pandas, at least, is programmed using an object-oriented paradigm. \n\n#### R\n\n<!-- R is a bit of a trickier case.  -->\n<!-- R has several different types of object-oriented structures that we usually avoid talking about until you start looking at developing your own R packages.  -->\n<!-- R also was designed by people who enjoyed using Lisp - another multi-paradigm approach that accommodates functional programming, procedural programming, and object-oriented programming.  -->\nAn easy example of R's object oriented nature is that when you fit different models or perform different tests, the default output is different. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(mtcars)\n\nr1 <- t.test(mtcars$mpg~mtcars$vs)\nprint(r1)\n## \n## \tWelch Two Sample t-test\n## \n## data:  mtcars$mpg by mtcars$vs\n## t = -4.6671, df = 22.716, p-value = 0.0001098\n## alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n## 95 percent confidence interval:\n##  -11.462508  -4.418445\n## sample estimates:\n## mean in group 0 mean in group 1 \n##        16.61667        24.55714\n\nr2 <- lm(mtcars$mpg ~ mtcars$vs)\nprint(r2)\n## \n## Call:\n## lm(formula = mtcars$mpg ~ mtcars$vs)\n## \n## Coefficients:\n## (Intercept)    mtcars$vs  \n##       16.62         7.94\n```\n:::\n\n\nThe output is different because each test/regression model object has a different print method, which allows R to create different output for each type of object. \n\n:::\n\n:::\n\nFunctional programming allows us to write programs that are more modular, and thus, are easier to test and debug.\nIn addition, functional programming encourages you to think about data **pipelines**: a sequence of steps that are reproducible and reusable for different data sets and analyses.\nFunctional programming is convenient for another (more esoteric, but important) reason - it allows you to prove that a function or series of functions is actually correct (rather than just testing input/output combinations). \n\n![A pipeline of functional data analysis. Each function (station) modifies the data in some way and the returned result is passed into the next function (station) as input. This allows a sequence of functions to format data, visualize it, model it, and then package the results. While this paradigm doesn't require a functional approach, functional programming does make it simpler. Modified from [Allison Horst's work](https://github.com/allisonhorst/stats-illustrations)](../images/wrangling/functional-pipeline.png){fig-alt=\"Cute fuzzy monsters putting rectangular data tables onto a conveyor belt. Along the conveyor belt line are different automated “stations” that update the data. A monster at the end of the conveyor belt is carrying away a table that reads “Complete analysis.”\"}\n\nIf you have been using the R pipe (`|>` or `%>%`), you didn't realize it, but you were already using functional programming. Piping results from one function to another in a chain is a prime example of the \"pure function\" idea - it allows us to chain each step of a sequence together to create a sequence that is modular and testable.\n\n::: callout-demo\n\n## A simple example\n\nA **functional** is a function that takes another function as input and returns a vector as output.\n\nOne simple example of a functional that is found in both R and Python is the `apply` function (or variants in R like `lapply`, `sapply`, `tapply`). \nIn Python, `.apply` is a method in Pandas, but we can find an even more low-level equivalent in the ideas of **list comprehensions** and **map** functions. \n\nOne additional concept that is helpful before we start is the idea of a **lambda** function - a small anonymous function (that is, a function that is not  named or stored in a variable).\nLambda functions are great for filling in default arguments, but they have many other uses as well.\n\nCan you identify the lambda functions in each of the following examples?\n\n::: panel-tabset\n\n#### R\n\nThis code generates 5 draws from a normal random variable with the specified mean and standard deviation 1.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlapply(1:5, function(x) rnorm(5, mean = x, sd = 1))\n## [[1]]\n## [1]  0.7844732  0.5458855  2.6856326  1.7559665 -0.4001054\n## \n## [[2]]\n## [1] 1.442056 1.076509 1.400636 2.830355 2.535376\n## \n## [[3]]\n## [1] 3.955703 1.641053 3.359905 2.737607 3.229719\n## \n## [[4]]\n## [1] 2.265823 3.531397 3.740123 3.482406 4.615128\n## \n## [[5]]\n## [1] 5.745490 5.544178 3.567269 5.496116 3.657098\n```\n:::\n\n\nOr, if you have R 4.1.0 or above, you can use a shorthand version:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlapply(1:5, \\(x) rnorm(5, mean = x))\n## [[1]]\n## [1]  0.5223755  0.9727726  2.1336584 -1.3808117 -1.4572924\n## \n## [[2]]\n## [1] 2.153122 1.622573 4.000264 1.942847 2.287341\n## \n## [[3]]\n## [1] 0.8369215 1.9280923 5.4403008 2.1253377 1.6932850\n## \n## [[4]]\n## [1] 5.625940 3.544783 4.309515 4.251880 3.935484\n## \n## [[5]]\n## [1] 5.507890 5.992994 5.138893 5.093818 6.409564\n```\n:::\n\n\nThe `\\(x)` is shorthand for `function(x)` and allows you to quickly and easily define anonymous functions in R.\n\n\n#### Python\n\nThis code generates 5 draws from a normal random variable with the specified mean and standard deviation 1.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\n\n# List comprehension approach\nr1 = [np.random.normal(i, size = 5) for i in range(1, 6)]\nprint(r1) \n\n# Functional approach\n# Defining a lambda function allows us to fill in non-default options\n## [array([0.34858138, 1.06976989, 2.25812385, 2.20489928, 2.09988906]), array([2.79939143, 0.87516968, 2.09055283, 1.71574275, 2.13487098]), array([2.4460569 , 2.52031657, 3.88145622, 4.89585524, 2.37028254]), array([3.2435194 , 0.50410337, 3.42250203, 3.91447091, 3.97658263]), array([4.69819101, 5.02666752, 4.91307413, 5.09655756, 4.25409405])]\nr2 = map(lambda a: np.random.normal(a, size = 5), range(1, 6))\n\n# This is what map spits out by default\nprint(r2)\n# get your results back out with list()\n## <map object at 0x7f5cb97edd60>\nr2b = list(r2) \nprint(r2b)\n## [array([-0.72227486,  0.23422041,  1.44085186,  0.3437729 ,  2.48680515]), array([2.09901533, 1.76634399, 1.63572447, 2.53083383, 0.69961824]), array([1.3454929 , 1.42647061, 3.99342509, 2.48717821, 1.73113057]), array([2.15172537, 2.88369642, 4.91023504, 3.30804959, 2.87652509]), array([5.54227609, 4.95891652, 3.55124072, 5.5027717 , 6.5271068 ])]\n```\n:::\n\n\n:::\n\n:::\n\n## Replacing Loops\n\nOne really convenient application of functional programming is to replace loops. \nAs Hadley Wickham says in [-@advr], \n\n> the real downside of for loops is that they’re very flexible: a loop conveys that you’re iterating, but not what should be done with the results\n\nThat is, in many cases when programming with data, what we want is to iterate over a vector and return a vector of results. \nThis is a *perfect* use case for functional programming, since we're specifying both that we're iterating AND more explicitly collecting the results into a form that makes sense.\n\nIf we work with this definition of functional programming, then python list comprehensions are also a functional approach: they specify how the results are collected (usually by putting `[]` around the statement) and how the iteration will occur @rituraj_jainNestedListComprehensions2018.\n\nLet's look at a few examples.\n\n::: callout-demo\nSuppose we want to look at the Lego data and create a decade variable that describes the decade a set was first released.\n\n\n::: panel-tabset\n\n### base R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlego <- read.csv(\"https://raw.githubusercontent.com/srvanderplas/datasets/main/clean/lego_sets.csv\")\n\nlego$decade <- sapply(lego$year, \\(x) floor(x/10)*10)\nhead(lego[,c(\"set_num\", \"name\", \"year\", \"decade\")])\n##   set_num                       name year decade\n## 1   001-1                      Gears 1965   1960\n## 2  0011-2          Town Mini-Figures 1979   1970\n## 3  0011-3 Castle 2 for 1 Bonus Offer 1987   1980\n## 4  0012-1         Space Mini-Figures 1979   1970\n## 5  0013-1         Space Mini-Figures 1979   1970\n## 6  0014-1         Space Mini-Figures 1979   1970\n```\n:::\n\n\n\nStrictly speaking, this use of `sapply` isn't necessary - because R is vectorized by default, we could also have used `lego$decade <- floor(lego$year/10)*10`.\nHowever, there are functions in R that are not fully vectorized, and it is useful to know this approach for those use-cases as well, and it's easier to demonstrate this approach with a relatively simple use case.\n\n### R: `purrr`\n\nIn purrr, you can create anonymous functions using `~` with `.` as a placeholder. If you need more parameters, you can use `.x`, `.y` and `map2` (for now) or `.1`, `.2`, `.3`, `...` with `pmap`. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(purrr)\nlibrary(readr)\nlibrary(dplyr)\n\nlego <- read_csv(\"https://raw.githubusercontent.com/srvanderplas/datasets/main/clean/lego_sets.csv\")\n\nlego <- lego |> # Either pipe will work here\n  mutate(decade = purrr::map_int(year, ~floor(./10)*10))\n\nlego |> \n  select(set_num, name, year, decade) |> \n  head()\n## # A tibble: 6 × 4\n##   set_num name                        year decade\n##   <chr>   <chr>                      <dbl>  <int>\n## 1 001-1   Gears                       1965   1960\n## 2 0011-2  Town Mini-Figures           1979   1970\n## 3 0011-3  Castle 2 for 1 Bonus Offer  1987   1980\n## 4 0012-1  Space Mini-Figures          1979   1970\n## 5 0013-1  Space Mini-Figures          1979   1970\n## 6 0014-1  Space Mini-Figures          1979   1970\n```\n:::\n\n\n\n### Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nimport math\n\nlego = pd.read_csv(\"https://raw.githubusercontent.com/srvanderplas/datasets/main/clean/lego_sets.csv\")\nlego['decade'] = [math.floor(i/10)*10 for i in lego.year]\nlego[['set_num', 'name', 'year', 'decade']].head()\n##   set_num                        name  year  decade\n## 0   001-1                       Gears  1965    1960\n## 1  0011-2           Town Mini-Figures  1979    1970\n## 2  0011-3  Castle 2 for 1 Bonus Offer  1987    1980\n## 3  0012-1          Space Mini-Figures  1979    1970\n## 4  0013-1          Space Mini-Figures  1979    1970\n```\n:::\n\n\n\n:::\n:::\n\nFor a more interesting example, though, let's consider fitting a different linear regression for each generation of Pokemon, describing the relationship between HP (hit points) and CP (combat power, aka `total` in this dataset). \n\n::: callout-demo\n\n### Pokemon modeling\n\n::: panel-tabset\n\n#### base R\n\n::: {.cell}\n\n```{.r .cell-code}\npoke <- read.csv(\"https://raw.githubusercontent.com/srvanderplas/datasets/main/clean/pokemon_gen_1-9.csv\")\n# Get rid of mega pokemon - they're a different thing\npoke <- subset(poke, !grepl(\"Mega\", poke$variant))\n\n# Split into a list of data frames from each gen\npoke_gens <- split(poke, poke$gen)\n\n# Fit linear regressions for each generation of pokemon\nmodels <- lapply(poke_gens, \\(df) lm(total ~ hp, data = df))\n\n# Pull out coefficients and r-squared values\nresults <- lapply(models, \\(res) data.frame(coef1 = coef(res)[1], coef2 = coef(res)[2], rsq = summary(res)$r.squared)) \n\n# Join the results back into a data.frame\nresults <- do.call(\"rbind\", results) \n\nresults\n##      coef1    coef2       rsq\n## 1 262.4730 2.394032 0.3895255\n## 2 258.5815 2.133868 0.3165292\n## 3 245.3375 2.753912 0.2686807\n## 4 268.5792 2.792350 0.3500187\n## 5 189.1339 3.506458 0.5578802\n## 6 252.7434 2.798942 0.5278159\n## 7 234.9329 3.293730 0.4382885\n## 8 205.2726 3.500811 0.6042219\n## 9 236.8656 2.757408 0.4757028\n```\n:::\n\n\n#### Tidy R\nIn the tidyverse, we use `tidyr::nest()` to accomplish a similar thing to `split` in base R.\n\nThis approach is designed to work entirely within a single data frame, which keeps the environment relatively clean and ensures that each step's results are stored in a convenient, easy-to-find place.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(purrr)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(tidyr)\n\nres <- read_csv(\"https://raw.githubusercontent.com/srvanderplas/datasets/main/clean/pokemon_gen_1-9.csv\") %>%\n  # str_detect doesn't play nice with NAs, so replace NA with \"\"\n  mutate(variant = replace_na(variant, \"\")) %>%\n  # Remove mega pokemon\n  filter(str_detect(variant, \"Mega\", negate = T)) %>%\n  # Sub-data-frames\n  nest(.by = gen) %>%\n  # Fit model\n  mutate(model = map(data, ~lm(total ~ hp, data = .))) %>%\n  # Extract coefficients\n  mutate(res = map(model, ~data.frame(coef1 = coef(.)[1], coef2 = coef(.)[2], rsq = summary(.)$r.squared))) %>%\n  # Bind together\n  unnest(c(res))\nres\n## # A tibble: 9 × 6\n##     gen data                model  coef1 coef2   rsq\n##   <dbl> <list>              <list> <dbl> <dbl> <dbl>\n## 1     1 <tibble [269 × 15]> <lm>    262.  2.39 0.390\n## 2     2 <tibble [118 × 15]> <lm>    259.  2.13 0.317\n## 3     3 <tibble [173 × 15]> <lm>    245.  2.75 0.269\n## 4     4 <tibble [173 × 15]> <lm>    269.  2.79 0.350\n## 5     5 <tibble [236 × 15]> <lm>    189.  3.51 0.558\n## 6     6 <tibble [118 × 15]> <lm>    253.  2.80 0.528\n## 7     7 <tibble [133 × 15]> <lm>    235.  3.29 0.438\n## 8     8 <tibble [134 × 15]> <lm>    205.  3.50 0.604\n## 9     9 <tibble [123 × 15]> <lm>    237.  2.76 0.476\n```\n:::\n\n\n\n#### Python\n\nThis construct of storing everything inside a single data frame isn't as common in Python, but we can make it work with only a little extra effort. \n\n::: aside\nI am sure that the python code I've written here is a bit kludgy if you are more fluent in python/pandas than I am, so please feel free to submit a pull request to fix it if you know a better or more \"pretty\" way to do this.\n:::\n\nYou will need to `pip install statsmodels` to get the `statsmodels` [@seabold2010statsmodels] package that implements many basic statistical models. \nThe `scikit-learn` package [@scikitlearn] is another commonly used package [@menonLinearRegressionLines2018], but it does not have the easy accessor functions to pull out e.g. coefficients and r-squared values, so we'll use `statsmodels` here. \n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nfrom statsmodels.formula.api import ols\n\n# Create a function to fit a linear regression\n# There is probably a better way to do this flexibly,\n# but this approach is simple and useful for illustrative purposes\ndef pokereg(data):\n  x = data[[\"hp\"]].values\n  y = data[[\"total\"]].values\n  model = ols('total ~ hp', data)\n  results = model.fit()\n  return results\n\nres = pd.read_csv(\"https://raw.githubusercontent.com/srvanderplas/datasets/main/clean/pokemon_gen_1-9.csv\")\n\n# Replace NAs with \"\"\nres[\"variant\"] = [\"\" if pd.isna(i) else i for i in res.variant]\n# Remove mega pokemon\nres = res.query('~(variant.str.contains(\"(?:^[mM]ega)\"))')\n\n# Group data frames and apply regression function to each group\nres_reg = res.groupby(\"gen\").apply(pokereg)\n\n# Make results into a dataframe and rename the column as 'results'\nres_reg = pd.DataFrame.from_dict(res_reg).rename(columns = {0:'results'})\n\n# Get values of interest and store in new columns\nres_reg = res_reg.reset_index() # store gen in its own column\nres_reg['coef1'] = res_reg.results.map(lambda x: x.params[0])\nres_reg['coef2'] = res_reg.results.map(lambda x: x.params[1])\nres_reg['rsq'] = res_reg.results.map(lambda x: x.rsquared)\n\nres_reg[['gen', 'coef1', 'coef2', 'rsq']]\n##    gen       coef1     coef2       rsq\n## 0    1  262.472956  2.394032  0.389526\n## 1    2  258.581538  2.133868  0.316529\n## 2    3  245.337496  2.753912  0.268681\n## 3    4  268.579237  2.792350  0.350019\n## 4    5  189.133898  3.506458  0.557880\n## 5    6  252.743437  2.798942  0.527816\n## 6    7  234.932868  3.293730  0.438289\n## 7    8  205.272637  3.500811  0.604222\n## 8    9  236.865627  2.757408  0.475703\n```\n:::\n\n\nWhile this doesn't store our data in the same DataFrame as the model results, we do have a key that links the two: the `gen` variable is present in both `res` and `res_reg` and can be used to join the data to the regression results, if necessary.\n\n:::\n\n:::\n\n\n\n## References",
    "supporting": [
      "08-functional-prog_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}