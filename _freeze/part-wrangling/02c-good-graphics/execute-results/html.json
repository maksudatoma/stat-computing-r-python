{
  "hash": "f529a7db375e951180097607af37589a",
  "result": {
    "engine": "knitr",
    "markdown": "# Creating Good Charts {#sec-good-graphics}\n\n##  {{< fa bullseye >}} Objectives\n\n- Evaluate existing charts and develop new versions that improve accessibility and readability\n\n\nA chart is good if it allows the user to draw useful conclusions that are supported by data. Obviously, this definition depends on the purpose of the chart - a simple EDA chart is going to have a different purpose than a chart showing e.g. the predicted path of a hurricane, which people will use to make decisions about whether or not to evacuate.\n\nUnfortunately, while our visual system is *amazing*, it is not always as accurate as the computers we use to render graphics. We have physical limits in the number of colors we can perceive, our short term memory, attention, and our ability to accurately read information off of charts in different forms.\n\n## Perceptual and Cognitive Factors\n\n### Preattentive Features\n\nYou've almost certainly noticed that some graphical tasks are easier than others. \nPart of the reason for this is that certain tasks require active engagement and attention to search through the visual stimulus; others, however, just \"pop\" out of the background.\nWe call these features that just \"pop\" without active work **preattentive** features; technically, they are detected within the first 250ms of viewing a stimulus [@treisman_preattentive_1985].\n\nTake a look at @fig-preattentive1; can you spot the point that is different?\n\n\n\n\n::: {#fig-preattentive1 .cell layout-ncol=\"2\"}\n::: {.cell-output-display}\n![Shape](02c-good-graphics_files/figure-html/fig-preattentive1-1.png){#fig-preattentive1-1 width=1200}\n:::\n\n::: {.cell-output-display}\n![Color](02c-good-graphics_files/figure-html/fig-preattentive1-2.png){#fig-preattentive1-2 width=1200}\n:::\n\nTwo scatterplots with one point that is different. Can you easily spot the different point?\n:::\n\n\n\n\nColor and shape are commonly used graphical features that are processed pre-attentively. \nSome people suggest utilizing this to pack more dimensions into multivariate visualizations [@healey_high-speed_1996], but in general, knowing which features are processed more quickly (color/shape) and which are processed more slowly (combinations of preattentively processed features) allows you to design a chart that requires less cognitive effort to read.\n\nAs awesome as it is to be able to use preattentive features to process information, we should not use combinations of preattentive features to show different variables. Take a look at @fig-preattentive2 - part (a) shows the same grouping in color and shape, part (b) shows color and shape used to encode different variables. \n\n\n\n\n::: {#fig-preattentive2 .cell layout-ncol=\"2\"}\n::: {.cell-output-display}\n![Shape and Color (dual encoded)](02c-good-graphics_files/figure-html/fig-preattentive2-1.png){#fig-preattentive2-1 width=49.5%}\n:::\n\n::: {.cell-output-display}\n![Shape and Color (different variables)](02c-good-graphics_files/figure-html/fig-preattentive2-2.png){#fig-preattentive2-2 width=49.5%}\n:::\n\nTwo scatterplots. Can you easily spot the different point(s)?\n:::\n\n\n\n\nHere, it is easy to differentiate the points in @fig-preattentive2(a), because they are dual-encoded. However, it is very difficult to pick out the different groups of points in @fig-preattentive2(b) because the combination of preattentive features requires active attention to sort out.\n\n#### Takeaways {-}\n\nCareful use of preattentive features can reduce the cognitive effort required for viewers to perceive a chart. \n\nEncode only one variable using preattentive features, as combinations of preattentive features are not processed preattentively.\n\n### Color\n\nOur eyes are optimized for perceiving the yellow/green region of the color spectrum, as shown in @fig-sensitivity. Why? Well, our sun produces yellow light, and plants tend to be green. It's pretty important to be able to distinguish different shades of green (evolutionarily speaking) because it impacts your ability to feed yourself. There aren't that many purple or blue predators, so there is less selection pressure to improve perception of that part of the visual spectrum.\n\n![Sensitivity of the human eye to different wavelengths of visual light (Image from [Wikimedia commons](https://upload.wikimedia.org/wikipedia/commons/c/c0/Eyesensitivity.svg))](../images/wrangling/Eyesensitivity.png){#fig-sensitivity}\n\n\nNot everyone perceives color in the same way. Some individuals are [colorblind or color deficient](https://en.wikipedia.org/wiki/Color_blindness) [@wikipediacontributors23c]. We have 3 cones used for color detection, as well as cells called rods, which detect light intensity (brightness/darkness). In about 5% of the population (10% of XY individuals, \\<1% of XX individuals), one or more of the cones may be missing or malformed, leading to color blindness - a reduced ability to perceive different shades. The rods, however, function normally in almost all of the population, which means that light/dark contrasts are extremely safe, while contrasts based on the hue of the color are problematic in some instances.\n\n::: {.callout-note collapse=true}\n\n#### Colorblindness Testing\nYou can take a test designed to screen for colorblindness [here](https://www.eyeque.com/color-blind-test/test/)\n\nYour monitor may affect how you score on these tests - I am colorblind, but on some monitors, I can pass the test, and on some, I perform worse than normal. A different test is available [here](https://www.color-blindness.com/farnsworth-munsell-100-hue-color-vision-test/).\n\n![My results on one monitor](../images/wrangling/colorblindness_monitorLG.png) ![My results on a monitor that has a different tech and supposedly higher color fidelity](../images/wrangling/colorblindness_monitorDell.png)\n\n![The Munsell colorblindness test](../images/wrangling/colorblind_munsell.png) In reality, I know that I have issues with perceiving some shades of red, green, and brown. I have particular trouble with very dark or very light colors, especially when they are close to grey or brown.\n\n:::\n\n\nIn addition to colorblindness, there are other factors than the actual color value which are important in how we experience color, such as context.\n\n\n\n\n\n\n::: {#fig-checker-shadow .cell layout=\"[[70, 30]]\"}\n::: {.cell-output-display}\n![The original illusion](../images/wrangling/CheckerShadow.png){#fig-checker-shadow-1 width=100%}\n:::\n\n::: {.cell-output-display}\n![The illusion with the checkerboard and shadow removed](../images/wrangling/CheckerShadow2.png){#fig-checker-shadow-2 width=100%}\n:::\n\nThe color constancy illusion. The squares marked A and B are actually the same color.\n:::\n\n\n\n\nOur brains are extremely dependent on context and make excellent use of the large amounts of experience we have with the real world. \nAs a result, we implicitly \"remove\" the effect of things like shadows as we make sense of the input to the visual system. \nThis can result in odd things, like the checkerboard and shadow shown in @fig-checker-shadow - because we're correcting for the shadow, B looks lighter than A even though when the context is removed they are clearly the same shade.\n\n#### Takeaways\n\n- Do not use rainbow color gradient schemes \n    - because of the unequal perception of different wavelengths, these schemes are *misleading* - the color distance does not match the perceptual distance.\n- Avoid any scheme that uses green-yellow-red signaling if you have a target audience that may include colorblind people.\n- To \"colorblind-proof\" a graphic, you can use a couple of strategies:\n    - double encoding - where you use color, use another aesthetic (line type, shape) as well to help your colorblind readers out\n    - If you can print your chart out in black and white and still read it, it will be safe for colorblind users. This is the only foolproof way to do it!\n    - If you are using a color gradient, use a monochromatic color scheme where possible. This is perceived as light -\\> dark by colorblind people, so it will be correctly perceived no matter what color you use.\n    - If you have a bidirectional scale (e.g. showing positive and negative values), the safest scheme to use is purple - white - orange. In any color scale that is multi-hue, it is important to transition through white, instead of from one color to another directly.\n- Be conscious of what certain colors \"mean\"\n    - Leveraging common associations can make it easier to read a color scale and remember what it stands for (e.g. blue for cold, orange/red for hot is a natural scale, red = Republican and blue = Democrat in the US, white -\\> blue gradients for showing rainfall totals)\n    - Some colors can can provoke emotional responses that may not be desirable.[^10-graphics-2]\n    - It is also important to be conscious of the social baggage that certain color schemes may have - the pink/blue color scheme often used to denote gender can be unnecessarily polarizing, and it may be easier to use a colder color (blue or purple) for men and a warmer color (yellow, orange, lighter green) for women[^10-graphics-3].\n- There are packages such as `RColorBrewer` and `dichromat` that have color palettes which are aesthetically pleasing, and, in many cases, colorblind friendly (`dichromat` is better for that than `RColorBrewer`). You can also take a look at other [ways to find nice color palettes](https://lisacharlotterost.de/2016/04/22/Colors-for-DataVis/).\n\n[^10-graphics-2]: When the COVID-19 outbreak started, many maps were using white-to-red gradients to show case counts and/or deaths. [The emotional association between red and blood, danger, and death may have caused people to become more frightened than what was reasonable given the available information.](https://www.esri.com/arcgis-blog/products/product/mapping/mapping-coronavirus-responsibly/)\n\n[^10-graphics-3]: Lisa Charlotte Rost. [What to consider when choosing colors for data visualization.](https://www.dataquest.io/blog/what-to-consider-when-choosing-colors-for-data-visualization/)\n\n### Short Term Memory\n\nWe have a limited amount of memory that we can instantaneously utilize. This mental space, called **short-term memory**, holds information for active use, but only for a limited amount of time.\n\n::: callout-tip\n#### Try it out! {.unnumbered}\n\n<details>\n\n<summary>Click here, read the information, and then click to hide it.</summary>\n\n1 4 2 2 3 9 8 0 7 8\n\n</details>\n\n<details>\n\n<summary>Wait a few seconds, then expand this section</summary>\n\nWhat was the third number?\n\n</details>\n:::\n\nWithout rehearsing the information (repeating it over and over to yourself), the try it out task may have been challenging. Short term memory has a capacity of between 3 and 9 \"bits\" of information.\n\nIn charts and graphs, short term memory is important because we need to be able to associate information from e.g. a key, legend, or caption with information plotted on the graph. As a result, if you try to plot more than \\~6 categories of information, your reader will have to shift between the legend and the graph repeatedly, increasing the amount of cognitive labor required to digest the information in the chart.\n\nWhere possible, try to keep your legends to 6 or 7 characteristics.\n\n**Implications and Guidelines**\n\n-   Limit the number of categories in your legends to minimize the short term memory demands on your reader.\n\n    -   When using continuous color schemes, you may want to use a log scale to better show differences in value across orders of magnitude.\n\n-   Use colors and symbols which have implicit meaning to minimize the need to refer to the legend.\n\n-   Add annotations on the plot, where possible, to reduce the need to re-read captions.\n\n### Grouping and Sense-making\n\nImposing order on visual chaos.\n\n::: panel-tabset\n#### Ambiguous Images {.unnumbered}\n\nWhat does @fig-rabbit-duck look like to you?\n\n![Is it a rabbit, or a duck?](../images/wrangling/rabbitduck.png){#fig-rabbit-duck}\n\nWhen faced with ambiguity, our brains use available context and past experience to try to tip the balance between alternate interpretations of an image. When there is still some ambiguity, many times the brain will just decide to interpret an image as one of the possible options.\n\n#### Illusory Contours {.unnumbered}\n\n![Consider this image - what do you see?](../images/wrangling/IllusoryContour.png)\n\nDid you see something like \"3 circles, a triangle with a black outline, and a white triangle on top of that\"? In reality, there are 3 angles and 3 pac-man shapes. But, it's much more likely that we're seeing layers of information, where some of the information is obscured (like the \"mouth\" of the pac-man circles, or the middle segment of each side of the triangle). This explanation is simpler, and more consistent with our experience.\n\n#### Figure/Ground {.unnumbered}\n\nNow, look at the logo for the Pittsburgh Zoo.\n\n<img src=\"https://upload.wikimedia.org/wikipedia/en/5/5b/Pittsburgh_Zoo_%26_PPG_Aquarium_logo.svg\" alt=\"What do you see?\" width=\"80%\"/>\n\nDo you see the gorilla and lionness? Or do you see a tree? Here, we're not entirely sure which part of the image is the figure and which is the background.\n:::\n\nThe ambiguous figures shown above demonstrate that our brains are actively imposing order upon the visual stimuli we encounter. There are some heuristics for how this order is applied which impact our perception of statistical graphs.\n\nThe catchphrase of Gestalt psychology is\n\n> The whole is greater than the sum of the parts\n\nThat is, what we perceive and the meaning we derive from the visual scene is more than the individual components of that visual scene.\n\n![The Gestalt Heuristics help us to impose order on ambiguous visual stimuli](../images/wrangling/gestalt.jpg)\n\nYou can read about the gestalt rules [here](https://en.wikipedia.org/wiki/Principles_of_grouping), but they are also demonstrated in the figure above.\n\nIn graphics, we can leverage the gestalt principles of grouping to create order and meaning. If we color points by another variable, we are creating groups of similar points which assist with the perception of groups instead of individual observations. If we add a trend line, we create the perception that the points are moving \"with\" the line (in most cases), or occasionally, that the line is dividing up two groups of points. Depending on what features of the data you wish to emphasize, you might choose different aesthetics mappings, facet variables, and factor orders.\n\n::: callout-caution\nSuppose I want to emphasize the change in the murder rate between 1980 and 2010.\n\nI could use a bar chart (showing only the first 4 states alphabetically for space)\n\n::: panel-tabset\n#### R {.unnumbered}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfbiwide <- read.csv(\"https://github.com/srvanderplas/Stat151/raw/main/data/fbiwide.csv\")\nlibrary(dplyr)\n\nfbiwide %>%\n  filter(Year %in% c(1980, 2010)) %>%\n  filter(State %in% c(\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\")) %>%\n  ggplot(aes(x = State, y = Murder/Population*100000, fill = factor(Year))) +\n  geom_col(position = \"dodge\") +\n  coord_flip() +\n  ylab(\"Murders per 100,000 residents\")\n```\n\n::: {.cell-output-display}\n![](02c-good-graphics_files/figure-html/chart-emphasis-bar-r-1.png){width=1800}\n:::\n:::\n\n\n\n\n#### Python {.unnumbered}\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nfbiwide = r.fbiwide\nfbiwide = fbiwide.assign(YearFactor = pd.Categorical(fbiwide.Year))\nfbiwide = fbiwide.assign(Murder100k = fbiwide.Murder/fbiwide.Population * 100000)\n\nyr1980_2010 = fbiwide[fbiwide.Year.isin([1980,2010])]\nsubdata = yr1980_2010[yr1980_2010.State.isin([\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\"])]\n\n(\nggplot(subdata, aes(x = \"State\", y = \"Murder100k\", fill = \"YearFactor\")) +\n  geom_col(stat='identity', position = \"dodge\") +\n  coord_flip() +\n  ylab(\"Murders per 100,000 residents\")\n)\n## NameError: name 'ggplot' is not defined\n```\n:::\n\n\n\n:::\n\nOr, I could use a line chart\n\n::: panel-tabset\n#### R {.unnumbered}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfbiwide %>%\n  filter(Year %in% c(1980, 2010)) %>%\n  ggplot(aes(x = Year, y = Murder/Population*100000, group = State)) +\n  geom_line() +\n  ylab(\"Murders per 100,000 residents\")\n```\n\n::: {.cell-output-display}\n![](02c-good-graphics_files/figure-html/chart-emphasis-line-r-1.png){width=1800}\n:::\n:::\n\n\n\n\n#### Python {.unnumbered}\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n(\nggplot(yr1980_2010, aes(x = \"Year\", y = \"Murder100k\", group = \"State\")) +\n  geom_line() +\n  ylab(\"Murders per 100,000 residents\")\n)\n## NameError: name 'ggplot' is not defined\n```\n:::\n\n\n\n:::\n\nOr, I could use a box plot\n\n::: panel-tabset\n#### R {.unnumbered}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfbiwide %>%\n  filter(Year %in% c(1980, 2010)) %>%\n  ggplot(aes(x = factor(Year), y = Murder/Population*100000)) +\n  geom_boxplot() +\n  ylab(\"Murders per 100,000 residents\")\n```\n\n::: {.cell-output-display}\n![](02c-good-graphics_files/figure-html/chart-emphasis-boxplot-r-1.png){width=1800}\n:::\n:::\n\n\n\n\n#### Python {.unnumbered}\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\n(\nggplot(yr1980_2010, aes(x = \"YearFactor\", y = \"Murder100k\")) +\n  geom_boxplot() +\n  ylab(\"Murders per 100,000 residents\")\n)\n## NameError: name 'ggplot' is not defined\n```\n:::\n\n\n\n:::\n\nWhich one best demonstrates that in every state and region, the murder rate decreased?\n\nThe line segment plot connects related observations (from the same state) but allows you to assess similarity between the lines (e.g. almost all states have negative slope). \nThe same information goes into the creation of the other two plots, but the bar chart is extremely cluttered, and the boxplot doesn't allow you to connect single state observations over time. \nSo while you can see an aggregate relationship (overall, the average number of murders in each state per 100k residents decreased) you can't see the individual relationships.\n\n:::\n\nThe aesthetic mappings and choices you make when creating plots have a huge impact on the conclusions that you (and others) can easily make when examining those plots.[^10-graphics-4]\n\n[^10-graphics-4]: See [this paper](https://doi.org/10.1080/10618600.2016.1209116) for more details. This is the last chapter of my dissertation, for what it's worth. It was a lot of fun. (no sarcasm, seriously, it was fun!)\n\n## General guidelines for accuracy\n\nThere are certain tasks which are easier for us relative to other, similar tasks.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Which of the lines is the longest? Shortest? It is much easier to determine the relative length of the line when the ends are aligned. In fact, the line lengths are the same in both panels.](02c-good-graphics_files/figure-html/accuracy-guidelines-1.png){width=2100}\n:::\n:::\n\n\n\n\nWhen making judgments corresponding to numerical quantities, there is an order of tasks from easiest (1) to hardest (6), with equivalent tasks at the same level.[^10-graphics-5]\n\n[^10-graphics-5]: See [this paper](https://www.doi.org/10.2307/2288400) for the major source of this ranking; other follow-up studies have been integrated, but the essential order is largely unchanged. Note that most of the items in this ranking were not examined in the linked paper, but are a synthesis of different experiments and conceptual knowledge in psychology as well as statistical graphics.\n\n1.  Position (common scale)\n2.  Position (non-aligned scale)\n3.  Length, Direction, Angle, Slope\n4.  Area\n5.  Volume, Density, Curvature\n6.  Shading, Color Saturation, Color Hue\n\nIf we compare a pie chart and a stacked bar chart, the bar chart asks readers to make judgements of position on a non-aligned scale, while a pie chart asks readers to assess angle. This is one reason why pie charts are not preferable -- they make it harder on the reader, and as a result we are less accurate when reading information from pie charts.\n\nWhen creating a chart, it is helpful to consider which variables you want to show, and how accurate reader perception needs to be to get useful information from the chart. In many cases, less is more - you can easily overload someone, which may keep them from engaging with your chart at all. Variables which require the reader to notice small changes should be shown on position scales (x, y) rather than using color, alpha blending, etc.\n\nThere is also a general increase in dimensionality from 1-3 to 4 (2d) to 5 (3d). In general, showing information in 3 dimensions when 2 will suffice is misleading - the addition of that extra dimension causes an increase in chart area allocated to the item that is disproportionate to the actual area.\n\n\n\n\n\n\n\n\n\n![Here, the area and height both encode the same variable, leading to a far disproportionate number of pixels allocated to \"Stocks\" than \"Cash Investments\" (h/t Junk Charts). In the first chart, stocks make up 60% of the portfolio, but have 67.5% of the pixels; Cash makes up 5% of the portfolio but those investments represent 2.3% of the pixels.](../images/wrangling/3d_graphs_suck.jpg).\n\n[Ted ED: How to spot a misleading graph - Lea Gaslowitz](https://youtu.be/E91bGT9BjYk)\n\n[Business Insider: The Worst Graphs Ever](https://www.businessinsider.com/the-27-worst-charts-of-all-time-2013-6)\n\nExtra dimensions and other annotations are sometimes called \"chartjunk\" and should only be used if they contribute to the overall numerical accuracy of the chart (e.g. they should not just be for decoration).\n\n\n## References {#sec-good-graphics-refs}\n",
    "supporting": [
      "02c-good-graphics_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}