{
  "hash": "71220785ef3b914911227d3b0f32ca19",
  "result": {
    "engine": "knitr",
    "markdown": "# Creating Good Charts {#sec-good-graphics}\n\n##  {{< fa bullseye >}} Objectives\n\n- Understand what features make graphics effective\n- Evaluate existing charts for accessibility and readability\n- Make improvements to charts to increase comprehension and accessibility\n\nA chart is good if it allows the user to draw useful conclusions that are supported by data. Obviously, this definition depends on the purpose of the chart - a simple EDA chart is going to have a different purpose than a chart showing e.g. the predicted path of a hurricane, which people will use to make decisions about whether or not to evacuate.\n\nUnfortunately, while our visual system is *amazing*, it is not always as accurate as the computers we use to render graphics. We have physical limits in the number of colors we can perceive, our short term memory, attention, and our ability to accurately read information off of charts in different forms.\n\n## Perceptual and Cognitive Factors\n\n### Preattentive Features\n\nYou've almost certainly noticed that some graphical tasks are easier than others. \nPart of the reason for this is that certain tasks require active engagement and attention to search through the visual stimulus; others, however, just \"pop\" out of the background.\nWe call these features that just \"pop\" without active work **preattentive** features; technically, they are detected within the first 250ms of viewing a stimulus [@treisman_preattentive_1985].\n\nTake a look at @fig-preattentive1; can you spot the point that is different?\n\n::: {#fig-preattentive1 .cell layout-ncol=\"2\"}\n::: {.cell-output-display}\n![Shape](02c-good-graphics_files/figure-html/fig-preattentive1-1.png){#fig-preattentive1-1 width=1200}\n:::\n\n::: {.cell-output-display}\n![Color](02c-good-graphics_files/figure-html/fig-preattentive1-2.png){#fig-preattentive1-2 width=1200}\n:::\n\nTwo scatterplots with one point that is different. Can you easily spot the different point?\n:::\n\nColor and shape are commonly used graphical features that are processed pre-attentively. \nSome people suggest utilizing this to pack more dimensions into multivariate visualizations [@healey_high-speed_1996], but in general, knowing which features are processed more quickly (color/shape) and which are processed more slowly (combinations of preattentively processed features) allows you to design a chart that requires less cognitive effort to read.\n\nAs awesome as it is to be able to use preattentive features to process information, we should not use combinations of preattentive features to show different variables. Take a look at @fig-preattentive2 - part (a) shows the same grouping in color and shape, part (b) shows color and shape used to encode different variables. \n\n::: {#fig-preattentive2 .cell layout-ncol=\"2\"}\n::: {.cell-output-display}\n![Shape and Color (dual encoded)](02c-good-graphics_files/figure-html/fig-preattentive2-1.png){#fig-preattentive2-1 width=49.5%}\n:::\n\n::: {.cell-output-display}\n![Shape and Color (different variables)](02c-good-graphics_files/figure-html/fig-preattentive2-2.png){#fig-preattentive2-2 width=49.5%}\n:::\n\nTwo scatterplots. Can you easily spot the different point(s)?\n:::\n\nHere, it is easy to differentiate the points in @fig-preattentive2(a), because they are dual-encoded. However, it is very difficult to pick out the different groups of points in @fig-preattentive2(b) because the combination of preattentive features requires active attention to sort out.\n\n#### Takeaways {-}\n\nCareful use of preattentive features can reduce the cognitive effort required for viewers to perceive a chart. \n\nEncode only one variable using preattentive features, as combinations of preattentive features are not processed preattentively.\n\n### Color\n\nOur eyes are optimized for perceiving the yellow/green region of the color spectrum, as shown in @fig-sensitivity. Why? Well, our sun produces yellow light, and plants tend to be green. It's pretty important to be able to distinguish different shades of green (evolutionarily speaking) because it impacts your ability to feed yourself. There aren't that many purple or blue predators, so there is less selection pressure to improve perception of that part of the visual spectrum.\n\n![Sensitivity of the human eye to different wavelengths of visual light (Image from [Wikimedia commons](https://upload.wikimedia.org/wikipedia/commons/c/c0/Eyesensitivity.svg))](../images/wrangling/Eyesensitivity.png){#fig-sensitivity}\n\n\nNot everyone perceives color in the same way. Some individuals are [colorblind or color deficient](https://en.wikipedia.org/wiki/Color_blindness) [@wikipediacontributors23c]. We have 3 cones used for color detection, as well as cells called rods, which detect light intensity (brightness/darkness). In about 5% of the population (10% of XY individuals, \\<1% of XX individuals), one or more of the cones may be missing or malformed, leading to color blindness - a reduced ability to perceive different shades. The rods, however, function normally in almost all of the population, which means that light/dark contrasts are extremely safe, while contrasts based on the hue of the color are problematic in some instances.\n\n::: {.callout-note collapse=true}\n\n#### Colorblindness Testing\nYou can take a test designed to screen for colorblindness [here](https://eyeque.com/color-blind-test/)\n\nYour monitor may affect how you score on these tests - I am colorblind, but on some monitors, I can pass the test, and on some, I perform worse than normal. A different test is available [here](https://www.color-blindness.com/farnsworth-munsell-100-hue-color-vision-test/).\n\n![My results on one monitor](../images/wrangling/colorblindness_monitorLG.png) ![My results on a monitor that has a different tech and supposedly higher color fidelity](../images/wrangling/colorblindness_monitorDell.png)\n\n![The Munsell colorblindness test](../images/wrangling/colorblind_munsell.png) In reality, I know that I have issues with perceiving some shades of red, green, and brown. I have particular trouble with very dark or very light colors, especially when they are close to grey or brown.\n\n:::\n\n\nIn addition to colorblindness, there are other factors than the actual color value which are important in how we experience color, such as context.\n\n\n\n::: {#fig-checker-shadow .cell layout=\"[[70, 30]]\"}\n::: {.cell-output-display}\n![The original illusion](../images/wrangling/CheckerShadow.png){#fig-checker-shadow-1 width=100%}\n:::\n\n::: {.cell-output-display}\n![The illusion with the checkerboard and shadow removed](../images/wrangling/CheckerShadow2.png){#fig-checker-shadow-2 width=100%}\n:::\n\nThe color constancy illusion. The squares marked A and B are actually the same color.\n:::\n\nOur brains are extremely dependent on context and make excellent use of the large amounts of experience we have with the real world. \nAs a result, we implicitly \"remove\" the effect of things like shadows as we make sense of the input to the visual system. \nThis can result in odd things, like the checkerboard and shadow shown in @fig-checker-shadow - because we're correcting for the shadow, B looks lighter than A even though when the context is removed they are clearly the same shade.\n\n#### Takeaways\n\n- Do not use rainbow color gradient schemes \n    - because of the unequal perception of different wavelengths, these schemes are *misleading* - the color distance does not match the perceptual distance.\n- Avoid any scheme that uses green-yellow-red signaling if you have a target audience that may include colorblind people.\n- To \"colorblind-proof\" a graphic, you can use a couple of strategies:\n    - double encoding - where you use color, use another aesthetic (line type, shape) as well to help your colorblind readers out\n    - If you can print your chart out in black and white and still read it, it will be safe for colorblind users. This is the only foolproof way to do it!\n    - If you are using a color gradient, use a monochromatic color scheme where possible. This is perceived as light -\\> dark by colorblind people, so it will be correctly perceived no matter what color you use.\n    - If you have a bidirectional scale (e.g. showing positive and negative values), the safest scheme to use is purple - white - orange. In any color scale that is multi-hue, it is important to transition through white, instead of from one color to another directly.\n- Be conscious of what certain colors \"mean\"\n    - Leveraging common associations can make it easier to read a color scale and remember what it stands for\n        - blue for cold, orange/red for hot is a natural scale\n        - red = Republican and blue = Democrat in the US (since ~1980)\n        - white -\\> blue gradients for showing rainfall totals\n    - Some colors can can provoke emotional responses that may not be desirable.[^10-graphics-2]\n    - Consider the social baggage that certain color schemes may have\n        - pink/blue color scheme often used for gender may be polarizing\n        - Consider using a cooler color (blue or purple) for men and a warmer color (yellow, orange, lighter green) for women[^10-graphics-3].\n- There are packages such as `RColorBrewer` and `dichromat` that have color palettes which are aesthetically pleasing, and, in many cases, colorblind friendly (`dichromat` is better for that than `RColorBrewer`). You can also take a look at other [ways to find nice color palettes](https://lisacharlotterost.de/2016/04/22/Colors-for-DataVis/).\n\n[^10-graphics-2]: When the COVID-19 outbreak started, many maps were using white-to-red gradients to show case counts and/or deaths. [The emotional association between red and blood, danger, and death may have caused people to become more frightened than what was reasonable given the available information.](https://www.esri.com/arcgis-blog/products/product/mapping/mapping-coronavirus-responsibly/)\n\n[^10-graphics-3]: Lisa Charlotte Rost. [What to consider when choosing colors for data visualization.](https://www.dataquest.io/blog/what-to-consider-when-choosing-colors-for-data-visualization/)\n\n### Short Term Memory\n\nWe have a limited amount of memory that we can instantaneously utilize. This mental space, called **short-term memory**, holds information for active use, but only for a limited amount of time.\n\n::: callout-tip\n#### Try it out! {.unnumbered}\n\n<details>\n\n<summary>Click here, read the information, and then click to hide it.</summary>\n\n1 4 2 2 3 9 8 0 7 8\n\n</details>\n\n<details>\n\n<summary>Wait a few seconds, then expand this section</summary>\n\nWhat was the third number?\n\n</details>\n:::\n\nWithout rehearsing the information (repeating it over and over to yourself), the try it out task may have been challenging. Short term memory has a capacity of between 3 and 9 \"bits\" of information.\n\nIn charts and graphs, short term memory is important because we need to be able to associate information from e.g. a key, legend, or caption with information plotted on the graph. As a result, if you try to plot more than \\~6 categories of information, your reader will have to shift between the legend and the graph repeatedly, increasing the amount of cognitive labor required to digest the information in the chart.\n\nWhere possible, try to keep your legends to 6 or 7 characteristics.\n\n**Implications and Guidelines**\n\n-   Limit the number of categories in your legends to minimize the short term memory demands on your reader.\n\n    -   When using continuous color schemes, you may want to use a log scale to better show differences in value across orders of magnitude.\n\n-   Use colors and symbols which have implicit meaning to minimize the need to refer to the legend.\n\n-   Add annotations on the plot, where possible, to reduce the need to re-read captions.\n\n### Grouping and Sense-making\n\nImposing order on visual chaos.\n\n::: panel-tabset\n#### Ambiguous Images {.unnumbered}\n\nWhat does @fig-rabbit-duck look like to you?\n\n![Is it a rabbit, or a duck?](../images/wrangling/rabbitduck.png){#fig-rabbit-duck width=\"50%\" fig-alt=\"An ambiguous image: when viewed from the right side, it looks like a duck, and when viewed from the bottom side, it looks like a rabbit. The x and y axes are labeled as 'rabbit' and 'duck', respectively.\"}\n\nWhen faced with ambiguity, our brains use available context and past experience to try to tip the balance between alternate interpretations of an image. When there is still some ambiguity, many times the brain will just decide to interpret an image as one of the possible options.\n\n#### Illusory Contours {.unnumbered}\n\n![Consider this image - what do you see?](../images/wrangling/IllusoryContour.png){fig-alt=\"An Illusory contour. It appears to be 3 black circles arranged in a downward-pointing triangle, with a black outline of a triangle pointing upward, and a background-colored (white) downward pointing triangle overlaid on top of the two previously described triangles. In reality, what is shown is a sequence of three pac-man shapes, with the missing pieces oriented inwards, at approximately 30, 150, and 270 degrees from the positive x-axis, with three 60 degree acute angle shapes oriented at 90, 210, and 330 degrees from the positive x-axis. The appearance of two triangles superimposed is an illusory contour that results from Gestalt heuristics.\" }\n\nDid you see something like \"3 circles, a triangle with a black outline, and a white triangle on top of that\"? In reality, there are 3 angles and 3 pac-man shapes. But, it's much more likely that we're seeing layers of information, where some of the information is obscured (like the \"mouth\" of the pac-man circles, or the middle segment of each side of the triangle). This explanation is simpler, and more consistent with our experience.\n\n#### Figure/Ground {.unnumbered}\n\nNow, look at the logo for the Pittsburgh Zoo.\n\n![](https://upload.wikimedia.org/wikipedia/en/5/5b/Pittsburgh_Zoo_%26_PPG_Aquarium_logo.svg){fig-alt=\"The logo of the Pittsburgh Zoo, which manipulates figure-ground perception. If the black portion of the image is considered the figure, the viewer sees a tree and some birds flying; if the white portion of the image is considered the figure, then the viewer sees a gorilla facing a lion, with some fish jumping above the waves at the bottom of the image. When viewed for several minutes, the figure and ground tend to 'flip' back and forth.\" width=\"80%\"}\n\nDo you see the gorilla and lionness? Or do you see a tree? Here, we're not entirely sure which part of the image is the figure and which is the background.\n:::\n\nThe ambiguous figures shown above demonstrate that our brains are actively imposing order upon the visual stimuli we encounter. There are some heuristics for how this order is applied which impact our perception of statistical graphs.\n\nThe catchphrase of Gestalt psychology is\n\n> The whole is greater than the sum of the parts\n\nThat is, what we perceive and the meaning we derive from the visual scene is more than the individual components of that visual scene.\n\n![The Gestalt Heuristics help us to impose order on ambiguous visual stimuli](../images/wrangling/gestalt.jpg){fig-alt=\"The word GESTALT, written such that there is a white bar over the G, illustrating the principle of closure, the E is made up of black squares, indicating proximity, the S has a bar going through it such that the middle part of the S is behind the bar, illustrating continuation, the Ts are both striped, illustrating similarity, and the A and L are smushed together, with a tree appearing within the A (the bar is missing across the A) to illustrate figure/ground.\"}\n\nYou can read about the gestalt rules [here](https://en.wikipedia.org/wiki/Principles_of_grouping), but they are also demonstrated in the figure above.\n\nIn graphics, we can leverage the Gestalt principles of grouping to create order and meaning. \nIf we color points by another variable, we are creating groups of similar points which assist with the perception of groups instead of individual observations. \nIf we add a trend line, we create the perception that the points are moving \"with\" the line (in most cases), or occasionally, that the line is dividing up two groups of points. \nDepending on what features of the data you wish to emphasize, you might choose different aesthetics mappings, facet variables, and factor orders.\n\n::: callout-caution\nSuppose I want to emphasize the change in life expectancy between 1982 and 2007. For this, we'll use the Gapminder [@gapminder] data which is found in the `gapminder` packages in R and python. \n\nI could use a bar chart (showing only 4 countries for space):\n\n::: panel-tabset\n#### R {.unnumbered}\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(gapminder)\n\nlibrary(dplyr)\n\ngapminder %>%\n  filter(year %in% c(1982, 2007)) %>%\n  filter(country %in% c(\"Korea, Rep.\", \"China\", \"Afghanistan\", \"India\")) %>%\n  ggplot(aes(x = country, y = lifeExp, fill = factor(year))) +\n  geom_col(position = \"dodge\") +\n  coord_flip() +\n  ylab(\"Life Expectancy\")\n```\n\n::: {.cell-output-display}\n![](02c-good-graphics_files/figure-html/chart-emphasis-bar-r-1.png){width=1800}\n:::\n:::\n\n#### Python {.unnumbered}\n\n::: {.cell}\n\n```{.python .cell-code}\n# %pip install gapminder\nfrom gapminder import gapminder\nimport pandas as pd\nimport seaborn.objects as so\n\nmy_gap_82_07 = my_gap[my_gap.year.isin([1982,2007])]\n## NameError: name 'my_gap' is not defined\nsubdata = my_gap_82_07[my_gap_82_07.country.\\\n    isin([\"Korea, Rep.\", \"China\", \"Afghanistan\", \"India\"])]\n## NameError: name 'my_gap_82_07' is not defined\nsubdata = subdata.assign(yearFactor=pd.Categorical(subdata.year))\n## NameError: name 'subdata' is not defined\n\nplot = so.Plot(subdata, x = \"country\", y = \"lifeExp\", color = \"yearFactor\").\\\n  add(so.Bar(), so.Dodge()).\\\n  label(y = \"Life Expectancy\")\n## NameError: name 'subdata' is not defined\nplot.show()\n## NameError: name 'plot' is not defined\n```\n:::\n\n\n\n:::\n\nOr, I could use a line chart\n\n::: panel-tabset\n#### R {.unnumbered}\n\n::: {.cell}\n\n```{.r .cell-code}\ngapminder %>%\n  filter(year %in% c(1982, 2007)) %>%\n  filter(country %in% c(\"Korea, Rep.\", \"China\", \"Afghanistan\", \"India\")) %>%\n  ggplot(aes(x = year, y = lifeExp, color = country)) +\n  geom_line() +\n  ylab(\"Life Expectancy\")\n```\n\n::: {.cell-output-display}\n![](02c-good-graphics_files/figure-html/chart-emphasis-line-r-3.png){width=1800}\n:::\n:::\n\n#### Python {.unnumbered}\n\n::: {.cell}\n\n```{.python .cell-code}\nsubdata2 = my_gap_82_07[my_gap_82_07.country.\\\n    isin([\"Korea, Rep.\", \"China\", \"Afghanistan\", \"India\"])]\n## NameError: name 'my_gap_82_07' is not defined\n\nplot = so.Plot(subdata, x = \"year\", y = \"lifeExp\", color = \"country\").\\\n  add(so.Lines()).\\\n  label(y = \"Life Expectancy\")\n## NameError: name 'subdata' is not defined\nplot.show()\n## NameError: name 'plot' is not defined\n```\n:::\n\n\n\n:::\n\nOr, I could use a box plot\n\n::: panel-tabset\n#### R {.unnumbered}\n\n::: {.cell}\n\n```{.r .cell-code}\ngapminder |>\n  filter(year %in% c(1982, 2007)) |>\n  ggplot(aes(x = factor(year), y = lifeExp)) + \n  geom_boxplot() + \n  ylab(\"Life Expectancy\")\n```\n\n::: {.cell-output-display}\n![](02c-good-graphics_files/figure-html/chart-emphasis-boxplot-r-3.png){width=1800}\n:::\n:::\n\n#### Python {.unnumbered}\n\n::: {.cell}\n\n```{.python .cell-code}\nimport seaborn as sns\n\nsubdata3 = my_gap_82_07.assign(yearFactor=pd.Categorical(my_gap_82_07.year))\n## NameError: name 'my_gap_82_07' is not defined\n\nsns.boxplot(data = subdata3, x = \"year\", y = \"lifeExp\")\n## NameError: name 'subdata3' is not defined\nplt.show()\n```\n\n::: {.cell-output-display}\n![](02c-good-graphics_files/figure-html/chart-emphasis-boxplot-py-1.png){width=576}\n:::\n:::\n\n\n\n:::\n\nWhich one best demonstrates that in every country, the life expectancy increased?\n\nThe line segment plot connects related observations (from the same country) but allows you to assess similarity between the lines (e.g. almost all countries have positive slope). \nThe same information goes into the creation of the other two plots, but the bar chart is extremely cluttered, and the boxplot doesn't allow you to connect single country observations over time. \nSo while you can see an aggregate relationship (overall, the average life expectancy increased) you can't see the individual relationships.\n\n:::\n\nThe aesthetic mappings and choices you make when creating plots have a huge impact on the conclusions that you (and others) can easily make when examining those plots.[^10-graphics-4]\n\n[^10-graphics-4]: See [this paper](https://doi.org/10.1080/10618600.2016.1209116) for more details. This is the last chapter of my dissertation, for what it's worth. It was a lot of fun. (no sarcasm, seriously, it was fun!)\n\n## Representing Data Accurately\n\nIn order to read data off of a chart correctly, several things must happen in sequence:\n\n1. The data must be accurately written to the chart, that is, the transformation from data -> geometry must be accurate\n2. The geometric objects that make up the chart must be perceived accurately - the mapping from geometric object size or location to mental model of geometric object size or location must be correct.\n3. The mental model of geometric object size or location must be accurately converted to a numerical value. We know that this isn't lossless, but we hope that this is at least reasonably accurate. \n\nIf step 1 is not done correctly, the chart is misleading or inaccurate. \nHowever, steps 2 and 3 depend on our brains accurately **perceiving** and **estimating** information mentally. \nThese steps can involve a lot of effort, and as mental effort increases, we tend to take shortcuts. \nSometimes, these shortcuts work well, but not always.\n\nWhen you design a chart, it's good to consider what mental tasks viewers of your chart need to perform. \nThen, ask yourself whether there is an equivalent way to represent the data that requires fewer mental operations, or a different representation that requires **easier** mental calculations.\n\n::: {.cell}\n::: {.cell-output-display}\n![Which of the lines is the longest? Shortest? It is much easier to determine the relative length of the line when the ends are aligned. The three lines have the same length in both panels, but the operation is much more difficult when the lines do not start or end at the same place.](02c-good-graphics_files/figure-html/accuracy-guidelines-5.png){fig-alt='A chart with two panels. The left panel is labeled \\'Aligned scale\\' and features three lines of different lengths which all start at the bottom of the chart. The right panel is labeled \\'Unaligned scale\\' and features three lines of different lengths which start at different locations.  It is easier to compare the lengths of the lines in the left panel, since they all start in the same place.' width=75%}\n:::\n:::\n\nWhen making judgments corresponding to numerical quantities, there is an order of tasks from easiest (1) to hardest (6), with equivalent tasks at the same level.[^10-graphics-5]\n\n[^10-graphics-5]: See [this paper](https://www.doi.org/10.2307/2288400) for the major source of this ranking; other follow-up studies have been integrated, but the essential order is largely unchanged^[Interestingly, while it is widely believed that @clevelandGraphicalPerceptionTheory1984 established this hierarchy experimentally, only a few of the items were ranked based on experiments in that paper and the follow up papers.]. Most of the items in this ranking were not examined in the linked paper, but are a synthesis of different experiments and conceptual knowledge in psychology as well as statistical graphics. \n\n1.  Position (common scale)\n2.  Position (non-aligned scale)\n3.  Length, Direction, Angle, Slope\n4.  Area\n5.  Volume, Density, Curvature\n6.  Shading, Color Saturation, Color Hue\n\n\nIf we compare a pie chart and a stacked bar chart, the bar chart asks readers to make judgments of position on a non-aligned scale, while a pie chart asks readers to assess angle.\nThis is one reason why pie charts tend not to be a good general option -- people must compare values using area or angle instead of position or length, which is a more difficult judgment under most circumstances. \nWhen there are a limited number of categories (2-4) and you have data that is easily compared to quarters of a circle, it may be justifiable to use a pie chart over a stacked bar chart - some studies have shown that pie charts are preferable under these conditions. \nAs a general rule, though, we have an easier time comparing position than angle or area. \n\n::: {.cell layout-ncol=\"2\"}\n::: {.cell-output-display}\n![Stacked bar and pie charts showing the relative proportion of people in North America living in the US, Canada, and Mexico in 2007. Which chart is easier to read relative information (e.g. there are about 3x as many people living in Mexico as Canada) from? Which chart is easier to estimate raw proportions (e.g. the US makes up about 70% of the population of North America) from?](02c-good-graphics_files/figure-html/pie-vs-bar-1.png){fig-alt='A stacked bar chart showing the proportion of people living in North America by country' fig-scap='Stacked bar chart' width=1200}\n:::\n\n::: {.cell-output-display}\n![Stacked bar and pie charts showing the relative proportion of people in North America living in the US, Canada, and Mexico in 2007. Which chart is easier to read relative information (e.g. there are about 3x as many people living in Mexico as Canada) from? Which chart is easier to estimate raw proportions (e.g. the US makes up about 70% of the population of North America) from?](02c-good-graphics_files/figure-html/pie-vs-bar-2.png){fig-alt='A pie chart showing the proportion of people living in North America by country' fig-scap='Pie chart' width=1200}\n:::\n:::\n\n\n\nWhen creating a chart, it is helpful to consider which variables you want to show, and how accurate reader perception needs to be to get useful information from the chart. \nIn many cases, less is more - you can easily overload someone, which may keep them from engaging with your chart at all.\nVariables which require the reader to notice small changes should be shown on position scales (x, y) rather than using color, alpha blending, etc.\n\nConsider the hierarchy of graphical tasks again.\nYou may notice a general increase in dimensionality from 1-3 to 4 (2d) to 5 (3d). \nIn general, showing information in 3 dimensions when 2 will suffice can be misleading. \nJust *how* misleading depends a lot on the type of chart you're using.\nMost of the time, the addition of an extra dimension causes an increase in chart area allocated to the item that is disproportionate to the actual numerical value being represented.\n\n\n\n![Here, the area and height both encode the same variable, leading to a far disproportionate number of pixels allocated to \"Stocks\" than \"Cash Investments\" (h/t Junk Charts). In the first chart, stocks make up 60% of the portfolio, but have 67.5% of the pixels; Cash makes up 5% of the portfolio but those investments represent 2.3% of the pixels.](../images/wrangling/3d_graphs_suck.jpg){#fig-disproportionate-pixels fig-alt=\"A three-dimensional pie chart, where each of the sections has a different height - this seems to double-encode the value represented by the angle of the pie slice. As a result, the area of the chart devoted to one sector is vastly larger than the area of the chart devoted to the other sectors, even though the true values are not nearly so different.\"}\n\n[Ted ED: How to spot a misleading graph - Lea Gaslowitz](https://youtu.be/E91bGT9BjYk)\n\n[Business Insider: The Worst Graphs Ever](https://www.businessinsider.com/the-27-worst-charts-of-all-time-2013-6)\n\nExtra dimensions and other annotations are sometimes called \"chartjunk\" and should only be used if they contribute to the overall numerical accuracy of the chart (e.g. they should not just be for decoration).\n\n\n## References {#sec-good-graphics-refs}\n",
    "supporting": [
      "02c-good-graphics_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}