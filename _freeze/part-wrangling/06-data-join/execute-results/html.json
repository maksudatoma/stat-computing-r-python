{
  "hash": "95fda0cd0668280a79335d3b744d87e1",
  "result": {
    "markdown": "# Joining Data {#sec-data-join}\n\n\nThe final essential data tidying and transformation skill you need to acquire is joining tables. \nIt is common for data to be organized **relationally** - that is, certain aspects of the data apply to a group of data points, and certain aspects apply to individual data points, and there are relationships between the individual data points and the groups of data points that have to be documented.\n\n::: callout-demo\n## Relational Data Example: Primary School Records\n\nEach individual has certain characteristics:\n\n-   full_name\n-   gender\n-   birth date\n-   ID number\n\nEach student has specific characteristics:\n\n-   ID number\n-   parent name\n-   parent phone number\n-   medical information\n-   Class ID\n\nTeachers may also have additional information:\n\n-   ID number\n-   Class ID\n-   employment start date\n-   education level\n-   compensation level\n\nThere are also fields like grades, which occur for each student in each class, but multiple times a year.\n\n-   ID number\n-   Student ID\n-   Class ID\n-   year\n-   term number\n-   subject\n-   grade\n-   comment\n\nAnd for teachers, there are employment records on a yearly basis\n\n-   ID number\n-   Employee ID\n-   year\n-   rating\n-   comment\n\nBut each class also has characteristics that describe the whole class as a unit:\n\n-   location ID\n-   class ID\n-   meeting time\n-   grade level\n\nEach location might also have some logistical information attached:\n\n-   location ID\n-   room number\n-   building\n-   number of seats\n-   AV equipment\n\n![Primary School Database Schema](../images/wrangling/PrimarySchoolExample.png) <!-- <a href=\"https://dbdiagram.io/embed/5ef387179ea313663b3b048e\">Link to diagram of the database</a> -->\n\nWe could go on, but you can see that this data is hierarchical, but also relational: \n\n- each class has both a teacher and a set of students \n- each class is held in a specific location that has certain equipment\n\nIt would be silly to store this information in a single table (though it can be done) because all of the teacher information would be duplicated for each student in each class; all of the student's individual info would be duplicated for each grade. \nThere would be a lot of wasted storage space and the tables would be much more confusing as well.\n\nBut, relational data also means we have to put in some work when we have a question that requires information from multiple tables. \nSuppose we want a list of all of the birthdays in a certain class. \nWe would need to take the following steps:\n\n-   get the Class ID\n-   get any teachers that are assigned that Class ID - specifically, get their ID number\n-   get any students that are assigned that Class ID - specifically, get their ID number\n-   append the results from teachers and students so that there is a list of all individuals in the class\n-   look through the \"individual data\" table to find any individuals with matching ID numbers, and keep those individuals' birth days.\n\nIt is helpful to develop the ability to lay out a set of tables in a schema (because often, database schemas aren't well documented) and mentally map out the steps that you need to combine tables to get the information you want from the information you have.\n:::\n\nTable joins allow us to combine information stored in different tables, keeping certain information (the stuff we need) while discarding extraneous information.\n\n**keys** are values that are found in multiple tables that can be used to connect the tables. A key (or set of keys) uniquely identify an observation. \nA **primary key** identifies an observation in its own table. \nA **foreign key** identifies an observation in another table.\n\nThere are 3 main types of table joins:\n\n-   Mutating joins, which add columns from one table to matching rows in another table\\\n    Ex: adding birthday to the table of all individuals in a class\n\n-   Filtering joins, which remove rows from a table based on whether or not there is a matching row in another table (but the columns in the original table don't change)\\\n    Ex: finding all teachers or students who have class ClassID\n\n-   Set operations, which treat observations as set elements (e.g. union, intersection, etc.)\\\n    Ex: taking the union of all student and teacher IDs to get a list of individual IDs\n\n### Animating Joins\n\nNote: all of these animations are stolen from https://github.com/gadenbuie/tidyexplain.\n\nIf we start with two tables, x and y,\n\n![](../images/wrangling/original-dfs.png)\n\n#### Mutating Joins\n\nWe're primarily going to focus on mutating joins, as filtering joins can be accomplished by ... filtering ... rather than by table joins.\n\n::: panel-tabset\n##### Inner Join\n\nWe can do a filtering `inner_join` to keep only rows which are in both tables (but we keep all columns)\n\n![](../images/wrangling/inner-join.gif)\n\n##### Left Join\n\nBut what if we want to keep all of the rows in x? We would do a `left_join`\n\n![](../images/wrangling/left-join.gif)\n\nIf there are multiple matches in the y table, though, we might have to duplicate rows in x. This is still a left join, just a more complicated one.\n\n![](../images/wrangling/left-join-extra.gif)\n\n##### Right Join\n\nIf we wanted to keep all of the rows in y, we would do a `right_join`:\n\n![](../images/wrangling/right-join.gif)\n\n(or, we could do a left join with y and x, but... either way is fine).\n\n##### Full Join\n\nAnd finally, if we want to keep all of the rows, we'd do a `full_join`:\n\n![](../images/wrangling/full-join.gif)\n\nYou can find other animations corresponding to filtering joins and set operations [here](https://github.com/gadenbuie/tidyexplain)\n:::\n\nEvery join has a \"left side\" and a \"right side\" - so in `some_join(A, B)`, A is the left side, B is the right side.\n\nJoins are differentiated based on how they treat the rows and columns of each side. \nIn mutating joins, the columns from both sides are always kept.\n\n+-------+-----------+------------+----------+\n|       | Left Side | Right Side |          |\n+-------+-----------+------------+----------+\n|       | Join Type | Rows       | Cols     |\n+-------+-----------+------------+----------+\n| inner | matching  | all        | matching |\n+-------+-----------+------------+----------+\n| left  | all       | all        | matching |\n+-------+-----------+------------+----------+\n| right | matching  | all        | all      |\n+-------+-----------+------------+----------+\n| outer | all       | all        | all      |\n+-------+-----------+------------+----------+\n\n::: callout-demo\n##### Demo: Mutating Joins\n\n::: panel-tabset\n###### R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tibble)\nlibrary(dplyr)\nt1 <- tibble(x = c(\"A\", \"B\", \"D\"), y = c(1, 2, 3))\nt2 <- tibble(x = c(\"B\", \"C\", \"D\"), z = c(2, 4, 5))\n```\n:::\n\n\nAn inner join keeps only rows that exist on both sides, but keeps all columns.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninner_join(t1, t2)\n## # A tibble: 2 × 3\n##   x         y     z\n##   <chr> <dbl> <dbl>\n## 1 B         2     2\n## 2 D         3     5\n```\n:::\n\n\nA left join keeps all of the rows in the left side, and adds any columns from the right side that match rows on the left. Rows on the left that don't match get filled in with NAs.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nleft_join(t1, t2)\n## # A tibble: 3 × 3\n##   x         y     z\n##   <chr> <dbl> <dbl>\n## 1 A         1    NA\n## 2 B         2     2\n## 3 D         3     5\nleft_join(t2, t1)\n## # A tibble: 3 × 3\n##   x         z     y\n##   <chr> <dbl> <dbl>\n## 1 B         2     2\n## 2 C         4    NA\n## 3 D         5     3\n```\n:::\n\n\nThere is a similar construct called a right join that is equivalent to flipping the arguments in a left join. The row and column ordering may be different, but all of the same values will be there\n\n\n::: {.cell}\n\n```{.r .cell-code}\nright_join(t1, t2)\n## # A tibble: 3 × 3\n##   x         y     z\n##   <chr> <dbl> <dbl>\n## 1 B         2     2\n## 2 D         3     5\n## 3 C        NA     4\nright_join(t2, t1)\n## # A tibble: 3 × 3\n##   x         z     y\n##   <chr> <dbl> <dbl>\n## 1 B         2     2\n## 2 D         5     3\n## 3 A        NA     1\n```\n:::\n\n\nAn outer join keeps everything - all rows, all columns. In dplyr, it's known as a `full_join`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull_join(t1, t2)\n## # A tibble: 4 × 3\n##   x         y     z\n##   <chr> <dbl> <dbl>\n## 1 A         1    NA\n## 2 B         2     2\n## 3 D         3     5\n## 4 C        NA     4\n```\n:::\n\n\n###### Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# This works because I already created the objects in R\n# and have the reticulate package loaded\nt1 = r.t1\nt2 = r.t2\n```\n:::\n\n\nAn inner join keeps only rows that exist on both sides, but keeps all columns.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\npd.merge(t1, t2, on = ['x']) # inner is default\n##    x    y    z\n## 0  B  2.0  2.0\n## 1  D  3.0  5.0\n```\n:::\n\n\nA left join keeps all of the rows in the left side, and adds any columns from the right side that match rows on the left. Rows on the left that don't match get filled in with NAs.\n\n\n::: {.cell}\n\n```{.python .cell-code}\npd.merge(t1, t2, on  = 'x', how = 'left')\n##    x    y    z\n## 0  A  1.0  NaN\n## 1  B  2.0  2.0\n## 2  D  3.0  5.0\npd.merge(t2, t1, on = 'x', how = 'left')\n##    x    z    y\n## 0  B  2.0  2.0\n## 1  C  4.0  NaN\n## 2  D  5.0  3.0\n```\n:::\n\n\nThere is a similar construct called a right join that is equivalent to flipping the arguments in a left join. The row and column ordering may be different, but all of the same values will be there\n\n\n::: {.cell}\n\n```{.python .cell-code}\npd.merge(t1, t2, on  = 'x', how = 'right')\n##    x    y    z\n## 0  B  2.0  2.0\n## 1  C  NaN  4.0\n## 2  D  3.0  5.0\npd.merge(t2, t1, on = 'x', how = 'right')\n##    x    z    y\n## 0  A  NaN  1.0\n## 1  B  2.0  2.0\n## 2  D  5.0  3.0\n```\n:::\n\n\nAn outer join keeps everything - all rows, all columns.\n\n\n::: {.cell}\n\n```{.python .cell-code}\npd.merge(t1, t2, on  = 'x', how = 'outer')\n##    x    y    z\n## 0  A  1.0  NaN\n## 1  B  2.0  2.0\n## 2  D  3.0  5.0\n## 3  C  NaN  4.0\n```\n:::\n\n:::\n:::\n\nI've included the other types of joins as animations because the animations are so useful for understanding the concept, but feel free to read through more information on these types of joins [here](https://r4ds.had.co.nz/relational-data.html#filtering-joins) [@r4ds].\n\n#### Filtering Joins\n\n::: panel-tabset\n##### Semi Join\n\nA semi join keeps matching rows from x and y, discarding all other rows and keeping only the columns from x.\n\n![](../images/wrangling/semi-join.gif)\n\n##### Anti Join\n\nAn anti-join keeps rows in x that do not have a match in y, and only keeps columns in x.\n\n![](../images/wrangling/anti-join.gif)\n:::\n\n#### Set Operations\n\n::: panel-tabset\n##### Union\n\nAll unique rows from x and y\n\n![](../images/wrangling/union.gif)\n\nOr, all unique rows from y and x.\n\n![](../images/wrangling/union-rev.gif)\n\n##### Union All\n\nAll rows from x and y, keeping duplicate rows.\n\n![](../images/wrangling/union-all.gif)\n\n##### Intersection\n\nCommon rows in x and y, keeping only unique rows.\n\n![](../images/wrangling/intersect.gif)\n\n##### Set Difference\n\nAll rows from x which are not also rows in y, keeping unique rows.\n\n![](../images/wrangling/setdiff.gif)\n\n![](../images/wrangling/setdiff-rev.gif)\n:::\n\n### Example: NYC Flights\n\nWe'll use the `nycflights13` package in R. \nUnfortunately, the data in this package are too big for me to reasonably store on github (you'll recall, I had to use a small sample the last time we played with this data...). \nSo before we can work with this data, we have to load the tables into Python.\n\n::: panel-tabset\n#### Loading Data: R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!\"nycflights13\" %in% installed.packages()) install.packages(\"nycflights13\")\nif (!\"dbplyr\" %in% installed.packages()) install.packages(\"dbplyr\")\nlibrary(nycflights13)\nlibrary(dbplyr)\nlibrary(reticulate)\n# This saves the database to a sqlite db file.\n# You will want to specify your own path\nnycflights13_sqlite(path = \"../data/\")\n## <SQLiteConnection>\n##   Path: /home/susan/Projects/Class/stat-computing-r-python/data/nycflights13.sqlite\n##   Extensions: TRUE\n```\n:::\n\n\n#### Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport sqlite3\ncon = sqlite3.connect(\"../data/nycflights13.sqlite\")\ncur = con.cursor()\n```\n:::\n\n:::\n\n[I am not going to cover SQLITE commands here - I'm just going to use the bare minimum, but you can find a very nice [introduction to python and SQLITE at datacarpentry](https://datacarpentry.org/python-ecology-lesson/09-working-with-sql/index.html) [@thecarpentriesAccessingSQLiteDatabases2022], and an [introduction to the dbplyr package](https://cran.r-project.org/web/packages/dbplyr/vignettes/dbplyr.html) for a nice R-SQLITE interface.]{.aside}\n\n::: callout-tip\n#### Try it out: Understanding Relational Data\n\n::: panel-tabset\n##### Problem\n\nSketch a diagram of which fields in each table match fields in other tables. \nUse the [data documentation](https://nycflights13.tidyverse.org/reference/index.html) to help you with your sketch.\n\n##### Solution\n\n![The nycflights database schema](https://d33wubrfki0l68.cloudfront.net/245292d1ea724f6c3fd8a92063dcd7bfb9758d02/5751b/diagrams/relational-nycflights.png) [here](https://r4ds.had.co.nz/relational-data.html#nycflights13-relational) (scroll down a bit).\n:::\n:::\n\n::: callout-caution\n#### Mutating Joins\n\nThese functions may become a bit more interesting once we try them out on real-world data. \nUsing the flights data, let's determine whether there's a relationship between the age of a plane and its delays.\n\n::: panel-tabset\n##### R\n\n\n::: {.cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\nlibrary(nycflights13)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\n\nplane_age <- planes %>%\n  mutate(age = 2013 - year) %>% # This gets us away from having to deal with 2 different year columns\n  select(tailnum, age, manufacturer)\n\ndelays_by_plane <- flights %>%\n  select(dep_delay, arr_delay, carrier, flight, tailnum)\n\n# We only need to keep delays that have a plane age, so use inner join\nres <- inner_join(delays_by_plane, plane_age, by = \"tailnum\")\n\nggplot(res, aes(x = age, y = dep_delay, group = cut_width(age, 1, center = 0))) + \n  geom_boxplot() + \n  ylab(\"Departure Delay (min)\") + \n  xlab(\"Plane age\") + \n  coord_cartesian(ylim = c(-20, 50))\n\nggplot(res, aes(x = age, y = arr_delay, group = cut_width(age, 1, center = 0))) + \n  geom_boxplot() + \n  ylab(\"Arrival Delay (min)\") + \n  xlab(\"Plane age\") + \n  coord_cartesian(ylim = c(-30, 60))\n```\n\n::: {.cell-output-display}\n![](06-data-join_files/figure-html/flights-delay-age-R-1.png){width=45%}\n:::\n\n::: {.cell-output-display}\n![](06-data-join_files/figure-html/flights-delay-age-R-2.png){width=45%}\n:::\n:::\n\n\nIt doesn't look like there's much of a relationship to me. \nIf anything, older planes are more likely to be early, but I suspect there aren't enough of them to make that conclusion (3.54% are over 25 years old, and 0.28% are over 40 years old).\n\n##### Python\n\n\n::: {.cell layout-ncol=\"2\"}\n\n```{.python .cell-code}\nimport pandas as pd\nimport sqlite3\nfrom plotnine import *\ncon = sqlite3.connect(\"../data/nycflights13.sqlite\")\n\nplanes = pd.read_sql_query(\"SELECT * FROM planes\", con)\nflights = pd.read_sql_query(\"SELECT * FROM flights\", con)\n\ncon.close() # close connection\n\nplane_age = planes.assign(age = lambda df: 2013 - df.year).loc[:,[\"tailnum\", \"age\", \"manufacturer\"]]\n\ndelays_by_plane = flights.loc[:, [\"dep_delay\", \"arr_delay\", \"carrier\", \"flight\", \"tailnum\"]]\n\nres = pd.merge(plane_age, delays_by_plane, on = \"tailnum\", how = \"inner\")\n\n# cut_width isn't in plotnine, so we have to create the bins ourselves first\nage_bins = [i for i in range(2 + int(max(res.age)))] \nres = res.assign(agebin = pd.cut(res.age, age_bins))\n# res.agebin.value_counts(dropna=False)\n\n(\nggplot(res, aes(x = \"age\", y = \"dep_delay\", group = \"agebin\")) + \n  geom_boxplot() + \n  ylab(\"Departure Delay (min)\") + \n  xlab(\"Plane age\") + \n  coord_cartesian(ylim = [-20, 50])\n)\n## <ggplot: (8737441329951)>\n## \n## /home/susan/.local/lib/python3.10/site-packages/plotnine/layer.py:333: PlotnineWarning: stat_boxplot : Removed 9374 rows containing non-finite values.\n```\n\n::: {.cell-output-display}\n![](06-data-join_files/figure-html/flights-delay-age-py-1.png){width=45%}\n:::\n\n```{.python .cell-code}\n(\nggplot(res, aes(x = \"age\", y = \"arr_delay\", group = \"agebin\")) + \n  geom_boxplot() + \n  ylab(\"Arrival Delay (min)\") + \n  xlab(\"Plane age\") + \n  coord_cartesian(ylim = (-30, 60))\n)\n## <ggplot: (8737414965077)>\n## \n## /home/susan/.local/lib/python3.10/site-packages/plotnine/layer.py:333: PlotnineWarning: stat_boxplot : Removed 10317 rows containing non-finite values.\n```\n\n::: {.cell-output-display}\n![](06-data-join_files/figure-html/flights-delay-age-py-2.png){width=45%}\n:::\n:::\n\n:::\n:::\n\n## Example: Gas Prices Data\n\nThe US Energy Information Administration tracks gasoline prices, with data available on a weekly level since late 1994. \nYou can go to [this site](https://www.eia.gov/dnav/pet/hist/LeafHandler.ashx?n=pet&s=emm_epm0u_pte_nus_dpg&f=w) to see a nice graph of gas prices, along with a corresponding table. <!-- (or you can look at the screenshot below, as I don't really trust that the site design will stay the same...) -->\n\n![Gas prices at US EIA site](../images/wrangling/06_gas_prices_screenshot.png)\n\nThe data in the table is structured in a fairly easy to read form: each row is a month; each week in the month is a set of two columns: one for the date, one for the average gas price. \nWhile this data is definitely not tidy, it is readable.\n\nBut looking at the chart at the top of the page, it's not clear how we might get that chart from the data in the format it's presented here: to get a chart like that, we would need a table where each row was a single date, and there were columns for date and price. \nThat would be tidy form data, and so we have to get from the wide, human-readable form into the long, tidier form that we can graph.\n\n::: callout-tip\n### Try it out: Manual Formatting in Excel\n\n::: panel-tabset\n#### Problem\n\nAn excel spreadsheet of the data as downloaded in January 2023 is available [here](https://github.com/srvanderplas/datasets/raw/main/raw/gas_prices_updated.xlsx). \nCan you manually format the data (or even just the first year or two of data) into a long, skinny format?\n\nWhat steps are involved?\n\n#### Solution\n\n1.  Copy the year-month column, creating one vertical copy for every set of columns\n\n2.  Move each block of two columns down to the corresponding vertical copy\n\n3.  Delete empty rows\n\n4.  Format dates\n\n5.  Delete empty columns\n\n#### Video\n\n::: {#fig-excel-demo-video .youtube-video-container}\n<iframe width=\"736\" height=\"414\" src=\"https://www.youtube.com/embed/n70eAKJmzRo\" title=\"06 Tidying Gas Price Data (in Excel)\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n\n</iframe>\n\nHere is a video of me doing most of the cleaning steps - I skipped out on cleaning up the dates because Excel is miserable for working with dates.\n:::\n:::\n:::\n\n### Setup: Gas Price Data Cleaning\n\nFor the next two examples, we'll read the data in from the HTML table online and work to make it something we could e.g. plot. Before we can start cleaning, we have to read in the data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rvest) # scrape data from the web\nlibrary(xml2) # parse xml data\nurl <- \"https://www.eia.gov/dnav/pet/hist/LeafHandler.ashx?n=pet&s=emm_epm0u_pte_nus_dpg&f=w\"\n\nhtmldoc <- read_html(url)\ngas_prices_html <- html_table(htmldoc, fill = T, trim = T)[[5]][,1:11]\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\nTable: First 6 rows of gas prices data as read into R\n\n|Year-Month |Week 1   |Week 1 |Week 2   |Week 2 |Week 3   |Week 3 |Week 4   |Week 4 |Week 5   |Week 5 |\n|:----------|:--------|:------|:--------|:------|:--------|:------|:--------|:------|:--------|:------|\n|Year-Month |End Date |Value  |End Date |Value  |End Date |Value  |End Date |Value  |End Date |Value  |\n|1994-Nov   |         |       |         |       |         |       |11/28    |1.175  |         |       |\n|1994-Dec   |12/05    |1.143  |12/12    |1.118  |12/19    |1.099  |12/26    |1.088  |         |       |\n|           |         |       |         |       |         |       |         |       |         |       |\n|1995-Jan   |01/02    |1.104  |01/09    |1.111  |01/16    |1.102  |01/23    |1.110  |01/30    |1.109  |\n|1995-Feb   |02/06    |1.103  |02/13    |1.099  |02/20    |1.093  |02/27    |1.101  |         |       |\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\ngas_prices_html = pd.read_html(\"https://www.eia.gov/dnav/pet/hist/LeafHandler.ashx?n=pet&s=emm_epm0u_pte_nus_dpg&f=w\")[4]\n```\n:::\n\n    ('Year-Month', 'Year-Month')    ('Week 1', 'End Date')      ('Week 1', 'Value')  ('Week 2', 'End Date')      ('Week 2', 'Value')  ('Week 3', 'End Date')      ('Week 3', 'Value')  ('Week 4', 'End Date')      ('Week 4', 'Value')  ('Week 5', 'End Date')      ('Week 5', 'Value')    ('Unnamed: 11_level_0', 'Unnamed: 11_level_1')    ('Unnamed: 12_level_0', 'Unnamed: 12_level_1')\n--  ------------------------------  ------------------------  ---------------------  ------------------------  ---------------------  ------------------------  ---------------------  ------------------------  ---------------------  ------------------------  ---------------------  ------------------------------------------------  ------------------------------------------------\n 0  1994-Nov                        nan                                     nan      nan                                     nan      nan                                     nan      11/28                                     1.175  nan                                     nan                                                   nan                                               nan\n 1  1994-Dec                        12/05                                     1.143  12/12                                     1.118  12/19                                     1.099  12/26                                     1.088  nan                                     nan                                                   nan                                               nan\n 2  nan                             nan                                     nan      nan                                     nan      nan                                     nan      nan                                     nan      nan                                     nan                                                   nan                                               nan\n 3  1995-Jan                        01/02                                     1.104  01/09                                     1.111  01/16                                     1.102  01/23                                     1.11   01/30                                     1.109                                               nan                                               nan\n 4  1995-Feb                        02/06                                     1.103  02/13                                     1.099  02/20                                     1.093  02/27                                     1.101  nan                                     nan                                                   nan                                               nan\n\n\n::: callout-tip\n### Try it out: Formatting with Pivot Operations\n\n::: panel-tabset\n#### Problem\n\nCan you format the data in a long-skinny format for plotting using pivot operations without any database merges?\n\nWrite out a list of steps, and for each step, sketch out what the data frame should look like.\n\nHow do your steps compare to the steps you used for the manual approach?\n\n#### Sketch\n\n![Steps to work through the gas prices data cleaning process](../images/wrangling/gas-prices-steps.png){fig-alt=\"Step 1: set row names to be more descriptive and remove header row. Step 2: Remove empty columns and pivot to long form, with dates and values in the same column and a description column that indicates what type of data is in the value column. Step 3: separate the week and variable information into different columns, discarding the week label. Step 4: pivot wider, so that date and value information are each in a single column. Step 5: remove rows with no values and create a yyyy-mm-dd format date. Step 6: Convert date and value into appropriate types (date, numeric).\"}\n\n#### R solution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(magrittr) # pipe friendly operations\n\n# Function to clean up column names\n# Written as an extra function because it makes the code a lot cleaner\nfix_gas_names <- function(x) {\n  # Add extra header row information\n  paste(x, c(\"\", rep(c(\"Date\", \"Value\"), times = 5))) %>%\n    # trim leading/trailing spaces\n    str_trim() %>%\n    # replace characters in names that aren't ok for variables in R\n    make.names()\n}\n\n# Clean up the table a bit\ngas_prices_raw <- gas_prices_html %>%\n  set_names(fix_gas_names(names(.))) %>%\n  # remove first row that is really an extra header row\n  filter(Year.Month != \"Year-Month\") %>%\n  # get rid of empty rows\n  filter(Year.Month != \"\")\n\nhead(gas_prices_raw)\n## # A tibble: 6 × 11\n##   Year.Month Week.1.Date Week.…¹ Week.…² Week.…³ Week.…⁴ Week.…⁵ Week.…⁶ Week.…⁷\n##   <chr>      <chr>       <chr>   <chr>   <chr>   <chr>   <chr>   <chr>   <chr>  \n## 1 1994-Nov   \"\"          \"\"      \"\"      \"\"      \"\"      \"\"      11/28   1.175  \n## 2 1994-Dec   \"12/05\"     \"1.143\" \"12/12\" \"1.118\" \"12/19\" \"1.099\" 12/26   1.088  \n## 3 1995-Jan   \"01/02\"     \"1.104\" \"01/09\" \"1.111\" \"01/16\" \"1.102\" 01/23   1.110  \n## 4 1995-Feb   \"02/06\"     \"1.103\" \"02/13\" \"1.099\" \"02/20\" \"1.093\" 02/27   1.101  \n## 5 1995-Mar   \"03/06\"     \"1.103\" \"03/13\" \"1.096\" \"03/20\" \"1.095\" 03/27   1.102  \n## 6 1995-Apr   \"04/03\"     \"1.116\" \"04/10\" \"1.134\" \"04/17\" \"1.149\" 04/24   1.173  \n## # … with 2 more variables: Week.5.Date <chr>, Week.5.Value <chr>, and\n## #   abbreviated variable names ¹​Week.1.Value, ²​Week.2.Date, ³​Week.2.Value,\n## #   ⁴​Week.3.Date, ⁵​Week.3.Value, ⁶​Week.4.Date, ⁷​Week.4.Value\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# gas_prices_raw <- select(gas_prices_raw, -c(X, Date))\ngas_prices_long <- pivot_longer(gas_prices_raw, -Year.Month,\n                                names_to = \"variable\", values_to = \"value\")\n\nhead(gas_prices_long)\n## # A tibble: 6 × 3\n##   Year.Month variable     value\n##   <chr>      <chr>        <chr>\n## 1 1994-Nov   Week.1.Date  \"\"   \n## 2 1994-Nov   Week.1.Value \"\"   \n## 3 1994-Nov   Week.2.Date  \"\"   \n## 4 1994-Nov   Week.2.Value \"\"   \n## 5 1994-Nov   Week.3.Date  \"\"   \n## 6 1994-Nov   Week.3.Value \"\"\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngas_prices_sep <- separate(gas_prices_long, variable, into = c(\"extra\", \"week\", \"variable\"), sep = \"\\\\.\") %>%\n  select(-extra)\nhead(gas_prices_sep)\n## # A tibble: 6 × 4\n##   Year.Month week  variable value\n##   <chr>      <chr> <chr>    <chr>\n## 1 1994-Nov   1     Date     \"\"   \n## 2 1994-Nov   1     Value    \"\"   \n## 3 1994-Nov   2     Date     \"\"   \n## 4 1994-Nov   2     Value    \"\"   \n## 5 1994-Nov   3     Date     \"\"   \n## 6 1994-Nov   3     Value    \"\"\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngas_prices_wide <- pivot_wider(gas_prices_sep, id_cols = c(\"Year.Month\", \"week\"), names_from = variable, values_from = value)\nhead(gas_prices_wide)\n## # A tibble: 6 × 4\n##   Year.Month week  Date    Value  \n##   <chr>      <chr> <chr>   <chr>  \n## 1 1994-Nov   1     \"\"      \"\"     \n## 2 1994-Nov   2     \"\"      \"\"     \n## 3 1994-Nov   3     \"\"      \"\"     \n## 4 1994-Nov   4     \"11/28\" \"1.175\"\n## 5 1994-Nov   5     \"\"      \"\"     \n## 6 1994-Dec   1     \"12/05\" \"1.143\"\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngas_prices_date <- gas_prices_wide %>%\n  filter(nchar(Value) > 0) %>%\n  separate(Year.Month, into = c(\"Year\", \"Month\"), sep = \"-\") %>%\n  mutate(Date = paste(Year, Date, sep = \"/\")) %>%\n  select(-c(1:3))\n  \nhead(gas_prices_date)\n## # A tibble: 6 × 2\n##   Date       Value\n##   <chr>      <chr>\n## 1 1994/11/28 1.175\n## 2 1994/12/05 1.143\n## 3 1994/12/12 1.118\n## 4 1994/12/19 1.099\n## 5 1994/12/26 1.088\n## 6 1995/01/02 1.104\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lubridate)\ngas_prices <- gas_prices_date %>%\n  mutate(Date = ymd(Date),\n         Price.per.gallon = as.numeric(Value)) %>%\n  select(-Value)\n  \nhead(gas_prices)\n## # A tibble: 6 × 2\n##   Date       Price.per.gallon\n##   <date>                <dbl>\n## 1 1994-11-28             1.18\n## 2 1994-12-05             1.14\n## 3 1994-12-12             1.12\n## 4 1994-12-19             1.10\n## 5 1994-12-26             1.09\n## 6 1995-01-02             1.10\n```\n:::\n\n\n#### Python solution\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\n\ndef fix_gas_names(x):\n  xx = pd.Series(x)\n  # add extra stuff to x\n  y = [\"Date\", \"Value\"]*5\n  y = [\"\", *y, \"\", \"\"]\n  names = xx + ' ' + y\n  names = names.str.strip()\n  names = names.str.replace(\" \", \".\")\n  return list(names)\n\n\ngas_prices_raw = gas_prices_html.copy()\n\n# What do column names look like?\ngas_prices_raw.columns # Multi-Index \n# (https://stackoverflow.com/questions/25189575/pandas-dataframe-select-columns-in-multiindex)\n## MultiIndex([(         'Year-Month',          'Year-Month'),\n##             (             'Week 1',            'End Date'),\n##             (             'Week 1',               'Value'),\n##             (             'Week 2',            'End Date'),\n##             (             'Week 2',               'Value'),\n##             (             'Week 3',            'End Date'),\n##             (             'Week 3',               'Value'),\n##             (             'Week 4',            'End Date'),\n##             (             'Week 4',               'Value'),\n##             (             'Week 5',            'End Date'),\n##             (             'Week 5',               'Value'),\n##             ('Unnamed: 11_level_0', 'Unnamed: 11_level_1'),\n##             ('Unnamed: 12_level_0', 'Unnamed: 12_level_1')],\n##            )\ncolnames = fix_gas_names(gas_prices_raw.columns.get_level_values(0))\ncolnames\n\n# Set new column names\n## ['Year-Month', 'Week.1.Date', 'Week.1.Value', 'Week.2.Date', 'Week.2.Value', 'Week.3.Date', 'Week.3.Value', 'Week.4.Date', 'Week.4.Value', 'Week.5.Date', 'Week.5.Value', 'Unnamed:.11_level_0', 'Unnamed:.12_level_0']\ngas_prices_raw.columns = colnames\n\n# Drop any rows with NaN in Year-Month\ngas_prices_raw = gas_prices_raw.dropna(axis = 0, subset = ['Year-Month'])\n\n# Drop extra columns on the end\ngas_prices_raw = gas_prices_raw.iloc[:,0:11]\ngas_prices_raw.head()\n##   Year-Month Week.1.Date  Week.1.Value  ... Week.4.Value  Week.5.Date Week.5.Value\n## 0   1994-Nov         NaN           NaN  ...        1.175          NaN          NaN\n## 1   1994-Dec       12/05         1.143  ...        1.088          NaN          NaN\n## 3   1995-Jan       01/02         1.104  ...        1.110        01/30        1.109\n## 4   1995-Feb       02/06         1.103  ...        1.101          NaN          NaN\n## 5   1995-Mar       03/06         1.103  ...        1.102          NaN          NaN\n## \n## [5 rows x 11 columns]\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ngas_prices_long = pd.melt(gas_prices_raw, id_vars = 'Year-Month', var_name = 'variable')\ngas_prices_long.head()\n##   Year-Month     variable  value\n## 0   1994-Nov  Week.1.Date    NaN\n## 1   1994-Dec  Week.1.Date  12/05\n## 2   1995-Jan  Week.1.Date  01/02\n## 3   1995-Feb  Week.1.Date  02/06\n## 4   1995-Mar  Week.1.Date  03/06\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ngas_prices_sep = gas_prices_long\ngas_prices_sep[[\"extra\", \"week\", \"variable\"]] = gas_prices_sep.variable.str.split(r'\\.', expand = True)\ngas_prices_sep = gas_prices_sep.drop('extra', axis = 1)\ngas_prices_sep.head()\n##   Year-Month variable  value week\n## 0   1994-Nov     Date    NaN    1\n## 1   1994-Dec     Date  12/05    1\n## 2   1995-Jan     Date  01/02    1\n## 3   1995-Feb     Date  02/06    1\n## 4   1995-Mar     Date  03/06    1\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ngas_prices_wide = pd.pivot(gas_prices_sep, index=['Year-Month', 'week'], columns = 'variable', values = 'value')\ngas_prices_wide.head()\n## variable          Date  Value\n## Year-Month week              \n## 1994-Dec   1     12/05  1.143\n##            2     12/12  1.118\n##            3     12/19  1.099\n##            4     12/26  1.088\n##            5       NaN    NaN\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ngas_prices_date = gas_prices_wide.dropna(axis = 0, subset = ['Date', 'Value']).reset_index()\ngas_prices_date[['Year', 'Month']] = gas_prices_date['Year-Month'].str.split(r'-', expand = True)\ngas_prices_date['Date'] = gas_prices_date.Year + '/' + gas_prices_date.Date\ngas_prices_date['Date'] = pd.to_datetime(gas_prices_date.Date)\n\ngas_prices_date.head()\n## variable Year-Month week       Date  Value  Year Month\n## 0          1994-Dec    1 1994-12-05  1.143  1994   Dec\n## 1          1994-Dec    2 1994-12-12  1.118  1994   Dec\n## 2          1994-Dec    3 1994-12-19  1.099  1994   Dec\n## 3          1994-Dec    4 1994-12-26  1.088  1994   Dec\n## 4          1994-Nov    4 1994-11-28  1.175  1994   Nov\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\n\ngas_prices = gas_prices_date.drop([\"Year-Month\", \"Year\", \"Month\", \"week\"], axis = 1)\ngas_prices['Price_per_gallon'] = gas_prices.Value\ngas_prices = gas_prices.drop(\"Value\", axis = 1)\ngas_prices.head()\n## variable       Date Price_per_gallon\n## 0        1994-12-05            1.143\n## 1        1994-12-12            1.118\n## 2        1994-12-19            1.099\n## 3        1994-12-26            1.088\n## 4        1994-11-28            1.175\n```\n:::\n\n:::\n:::\n\n::: callout-tip\n### Try it out: Formatting using merge + pivot\n\n::: panel-tabset\n#### Problem\n\nCan you format the data in a long-skinny format for plotting using pivot operations using wide-to-long pivot operation(s) and a database merge?\n\nYou can start with the `gas_prices_raw`\n\nWrite out a list of steps, and for each step, sketch out what the data frame should look like.\n\nHow do your steps compare to the steps you used for the manual approach?\n\n#### Sketch\n\n![](../images/wrangling/gas-prices-steps2.png) \n\n#### R solution\n\nWe'll use the same data cleaning function as before:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Clean up the table a bit\ngas_prices_raw <- gas_prices_html %>%\n  set_names(fix_gas_names(names(.))) %>%\n  # remove first row that is really an extra header row\n  filter(Year.Month != \"Year-Month\") %>%\n  # get rid of empty rows\n  filter(Year.Month != \"\")\n\nhead(gas_prices_raw)\n## # A tibble: 6 × 11\n##   Year.Month Week.1.Date Week.…¹ Week.…² Week.…³ Week.…⁴ Week.…⁵ Week.…⁶ Week.…⁷\n##   <chr>      <chr>       <chr>   <chr>   <chr>   <chr>   <chr>   <chr>   <chr>  \n## 1 1994-Nov   \"\"          \"\"      \"\"      \"\"      \"\"      \"\"      11/28   1.175  \n## 2 1994-Dec   \"12/05\"     \"1.143\" \"12/12\" \"1.118\" \"12/19\" \"1.099\" 12/26   1.088  \n## 3 1995-Jan   \"01/02\"     \"1.104\" \"01/09\" \"1.111\" \"01/16\" \"1.102\" 01/23   1.110  \n## 4 1995-Feb   \"02/06\"     \"1.103\" \"02/13\" \"1.099\" \"02/20\" \"1.093\" 02/27   1.101  \n## 5 1995-Mar   \"03/06\"     \"1.103\" \"03/13\" \"1.096\" \"03/20\" \"1.095\" 03/27   1.102  \n## 6 1995-Apr   \"04/03\"     \"1.116\" \"04/10\" \"1.134\" \"04/17\" \"1.149\" 04/24   1.173  \n## # … with 2 more variables: Week.5.Date <chr>, Week.5.Value <chr>, and\n## #   abbreviated variable names ¹​Week.1.Value, ²​Week.2.Date, ³​Week.2.Value,\n## #   ⁴​Week.3.Date, ⁵​Week.3.Value, ⁶​Week.4.Date, ⁷​Week.4.Value\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngas_prices_dates <- select(gas_prices_raw, 1, matches(\"Week.[1-5].Date\"))\ngas_prices_values <- select(gas_prices_raw, 1, matches(\"Week.[1-5].Value\"))\n\nhead(gas_prices_dates)\n## # A tibble: 6 × 6\n##   Year.Month Week.1.Date Week.2.Date Week.3.Date Week.4.Date Week.5.Date\n##   <chr>      <chr>       <chr>       <chr>       <chr>       <chr>      \n## 1 1994-Nov   \"\"          \"\"          \"\"          11/28       \"\"         \n## 2 1994-Dec   \"12/05\"     \"12/12\"     \"12/19\"     12/26       \"\"         \n## 3 1995-Jan   \"01/02\"     \"01/09\"     \"01/16\"     01/23       \"01/30\"    \n## 4 1995-Feb   \"02/06\"     \"02/13\"     \"02/20\"     02/27       \"\"         \n## 5 1995-Mar   \"03/06\"     \"03/13\"     \"03/20\"     03/27       \"\"         \n## 6 1995-Apr   \"04/03\"     \"04/10\"     \"04/17\"     04/24       \"\"\nhead(gas_prices_values)\n## # A tibble: 6 × 6\n##   Year.Month Week.1.Value Week.2.Value Week.3.Value Week.4.Value Week.5.Value\n##   <chr>      <chr>        <chr>        <chr>        <chr>        <chr>       \n## 1 1994-Nov   \"\"           \"\"           \"\"           1.175        \"\"          \n## 2 1994-Dec   \"1.143\"      \"1.118\"      \"1.099\"      1.088        \"\"          \n## 3 1995-Jan   \"1.104\"      \"1.111\"      \"1.102\"      1.110        \"1.109\"     \n## 4 1995-Feb   \"1.103\"      \"1.099\"      \"1.093\"      1.101        \"\"          \n## 5 1995-Mar   \"1.103\"      \"1.096\"      \"1.095\"      1.102        \"\"          \n## 6 1995-Apr   \"1.116\"      \"1.134\"      \"1.149\"      1.173        \"\"\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngas_prices_dates_long <- pivot_longer(gas_prices_dates, -Year.Month, names_to = \"week\", values_to = \"month_day\")\ngas_prices_values_long <- pivot_longer(gas_prices_values, -Year.Month, names_to = \"week\", values_to = \"price_per_gallon\")\n\nhead(gas_prices_dates_long)\n## # A tibble: 6 × 3\n##   Year.Month week        month_day\n##   <chr>      <chr>       <chr>    \n## 1 1994-Nov   Week.1.Date \"\"       \n## 2 1994-Nov   Week.2.Date \"\"       \n## 3 1994-Nov   Week.3.Date \"\"       \n## 4 1994-Nov   Week.4.Date \"11/28\"  \n## 5 1994-Nov   Week.5.Date \"\"       \n## 6 1994-Dec   Week.1.Date \"12/05\"\nhead(gas_prices_values_long)\n## # A tibble: 6 × 3\n##   Year.Month week         price_per_gallon\n##   <chr>      <chr>        <chr>           \n## 1 1994-Nov   Week.1.Value \"\"              \n## 2 1994-Nov   Week.2.Value \"\"              \n## 3 1994-Nov   Week.3.Value \"\"              \n## 4 1994-Nov   Week.4.Value \"1.175\"         \n## 5 1994-Nov   Week.5.Value \"\"              \n## 6 1994-Dec   Week.1.Value \"1.143\"\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lubridate) # ymd function\ngas_prices_dates_long_clean <- gas_prices_dates_long %>%\n  filter(month_day != \"\") %>%\n  mutate(week = str_extract(week, \"\\\\d\") %>% as.numeric()) %>%\n  mutate(year = str_extract(Year.Month, \"\\\\d{4}\"), \n         Date = paste(year, month_day, sep = \"/\") %>% \n           ymd())\n\ngas_prices_values_long_clean <- gas_prices_values_long %>%\n  filter(price_per_gallon != \"\") %>%\n  mutate(week = str_extract(week, \"\\\\d\") %>% as.numeric()) %>%\n  mutate(price_per_gallon = as.numeric(price_per_gallon))\n\nhead(gas_prices_dates_long_clean)\n## # A tibble: 6 × 5\n##   Year.Month  week month_day year  Date      \n##   <chr>      <dbl> <chr>     <chr> <date>    \n## 1 1994-Nov       4 11/28     1994  1994-11-28\n## 2 1994-Dec       1 12/05     1994  1994-12-05\n## 3 1994-Dec       2 12/12     1994  1994-12-12\n## 4 1994-Dec       3 12/19     1994  1994-12-19\n## 5 1994-Dec       4 12/26     1994  1994-12-26\n## 6 1995-Jan       1 01/02     1995  1995-01-02\nhead(gas_prices_values_long_clean)\n## # A tibble: 6 × 3\n##   Year.Month  week price_per_gallon\n##   <chr>      <dbl>            <dbl>\n## 1 1994-Nov       4             1.18\n## 2 1994-Dec       1             1.14\n## 3 1994-Dec       2             1.12\n## 4 1994-Dec       3             1.10\n## 5 1994-Dec       4             1.09\n## 6 1995-Jan       1             1.10\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngas_prices <- left_join(gas_prices_dates_long_clean, gas_prices_values_long_clean, by = c(\"Year.Month\", \"week\")) %>%\n  select(Date, price_per_gallon)\nhead(gas_prices)\n## # A tibble: 6 × 2\n##   Date       price_per_gallon\n##   <date>                <dbl>\n## 1 1994-11-28             1.18\n## 2 1994-12-05             1.14\n## 3 1994-12-12             1.12\n## 4 1994-12-19             1.10\n## 5 1994-12-26             1.09\n## 6 1995-01-02             1.10\n```\n:::\n\n\n#### Python solution\n\n\n::: {.cell}\n\n```{.python .cell-code}\ngas_prices_raw = gas_prices_html.copy()\n\n# What do column names look like?\ngas_prices_raw.columns # Multi-Index \n# (https://stackoverflow.com/questions/25189575/pandas-dataframe-select-columns-in-multiindex)\n## MultiIndex([(         'Year-Month',          'Year-Month'),\n##             (             'Week 1',            'End Date'),\n##             (             'Week 1',               'Value'),\n##             (             'Week 2',            'End Date'),\n##             (             'Week 2',               'Value'),\n##             (             'Week 3',            'End Date'),\n##             (             'Week 3',               'Value'),\n##             (             'Week 4',            'End Date'),\n##             (             'Week 4',               'Value'),\n##             (             'Week 5',            'End Date'),\n##             (             'Week 5',               'Value'),\n##             ('Unnamed: 11_level_0', 'Unnamed: 11_level_1'),\n##             ('Unnamed: 12_level_0', 'Unnamed: 12_level_1')],\n##            )\ncolnames = fix_gas_names(gas_prices_raw.columns.get_level_values(0))\ncolnames\n\n# Set new column names\n## ['Year-Month', 'Week.1.Date', 'Week.1.Value', 'Week.2.Date', 'Week.2.Value', 'Week.3.Date', 'Week.3.Value', 'Week.4.Date', 'Week.4.Value', 'Week.5.Date', 'Week.5.Value', 'Unnamed:.11_level_0', 'Unnamed:.12_level_0']\ngas_prices_raw.columns = colnames\n\n# Drop any rows with NaN in Year-Month\ngas_prices_raw = gas_prices_raw.dropna(axis = 0, subset = ['Year-Month'])\n\ngas_prices_raw.head()\n##   Year-Month Week.1.Date  ...  Unnamed:.11_level_0 Unnamed:.12_level_0\n## 0   1994-Nov         NaN  ...                  NaN                 NaN\n## 1   1994-Dec       12/05  ...                  NaN                 NaN\n## 3   1995-Jan       01/02  ...                  NaN                 NaN\n## 4   1995-Feb       02/06  ...                  NaN                 NaN\n## 5   1995-Mar       03/06  ...                  NaN                 NaN\n## \n## [5 rows x 13 columns]\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ngas_prices_dates = gas_prices_raw.filter(regex = 'Year-Month|Week.\\d.Date', axis = 1)\ngas_prices_values = gas_prices_raw.filter(regex = 'Year-Month|Week.\\d.Value', axis = 1)\n\ngas_prices_dates.head()\n##   Year-Month Week.1.Date Week.2.Date Week.3.Date Week.4.Date Week.5.Date\n## 0   1994-Nov         NaN         NaN         NaN       11/28         NaN\n## 1   1994-Dec       12/05       12/12       12/19       12/26         NaN\n## 3   1995-Jan       01/02       01/09       01/16       01/23       01/30\n## 4   1995-Feb       02/06       02/13       02/20       02/27         NaN\n## 5   1995-Mar       03/06       03/13       03/20       03/27         NaN\ngas_prices_values.head()\n##   Year-Month  Week.1.Value  ...  Week.4.Value  Week.5.Value\n## 0   1994-Nov           NaN  ...         1.175           NaN\n## 1   1994-Dec         1.143  ...         1.088           NaN\n## 3   1995-Jan         1.104  ...         1.110         1.109\n## 4   1995-Feb         1.103  ...         1.101           NaN\n## 5   1995-Mar         1.103  ...         1.102           NaN\n## \n## [5 rows x 6 columns]\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ngas_prices_dates_long = pd.melt(gas_prices_dates, id_vars = 'Year-Month', var_name = \"week\", value_name = \"month_day\")\ngas_prices_values_long = pd.melt(gas_prices_values, id_vars = 'Year-Month', var_name = \"week\", value_name = \"price_per_gallon\")\n\ngas_prices_dates_long.head()\n##   Year-Month         week month_day\n## 0   1994-Nov  Week.1.Date       NaN\n## 1   1994-Dec  Week.1.Date     12/05\n## 2   1995-Jan  Week.1.Date     01/02\n## 3   1995-Feb  Week.1.Date     02/06\n## 4   1995-Mar  Week.1.Date     03/06\ngas_prices_values_long.head()\n##   Year-Month          week  price_per_gallon\n## 0   1994-Nov  Week.1.Value               NaN\n## 1   1994-Dec  Week.1.Value             1.143\n## 2   1995-Jan  Week.1.Value             1.104\n## 3   1995-Feb  Week.1.Value             1.103\n## 4   1995-Mar  Week.1.Value             1.103\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ngas_prices_dates_long_clean = gas_prices_dates_long.dropna().copy()\ngas_prices_dates_long_clean[\"week\"] = gas_prices_dates_long_clean.week.str.extract(r\"Week.(\\d).Date\")\ngas_prices_dates_long_clean[\"year\"] = gas_prices_dates_long_clean[\"Year-Month\"].str.extract(r\"(\\d{4})-[A-z]{3}\")\ngas_prices_dates_long_clean[\"Date\"] = gas_prices_dates_long_clean.year + \"/\" + gas_prices_dates_long_clean.month_day\ngas_prices_dates_long_clean[\"Date\"] = pd.to_datetime(gas_prices_dates_long_clean.Date)\n\n\ngas_prices_values_long_clean = gas_prices_values_long.dropna().copy()\ngas_prices_values_long_clean[\"week\"] = gas_prices_values_long_clean.week.str.extract(r\"Week.(\\d).Value\")\ngas_prices_values_long_clean[\"price_per_gallon\"] = pd.to_numeric(gas_prices_values_long_clean[\"price_per_gallon\"])\n\ngas_prices_dates_long_clean.head()\n##   Year-Month week month_day  year       Date\n## 1   1994-Dec    1     12/05  1994 1994-12-05\n## 2   1995-Jan    1     01/02  1995 1995-01-02\n## 3   1995-Feb    1     02/06  1995 1995-02-06\n## 4   1995-Mar    1     03/06  1995 1995-03-06\n## 5   1995-Apr    1     04/03  1995 1995-04-03\ngas_prices_values_long_clean.head()\n##   Year-Month week  price_per_gallon\n## 1   1994-Dec    1             1.143\n## 2   1995-Jan    1             1.104\n## 3   1995-Feb    1             1.103\n## 4   1995-Mar    1             1.103\n## 5   1995-Apr    1             1.116\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ngas_prices = pd.merge(gas_prices_dates_long_clean, gas_prices_values_long_clean, on = (\"Year-Month\", \"week\")).loc[:,[\"Date\", \"price_per_gallon\"]]\ngas_prices.head()\n##         Date  price_per_gallon\n## 0 1994-12-05             1.143\n## 1 1995-01-02             1.104\n## 2 1995-02-06             1.103\n## 3 1995-03-06             1.103\n## 4 1995-04-03             1.116\n```\n:::\n\n:::\n:::\n",
    "supporting": [
      "06-data-join_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}